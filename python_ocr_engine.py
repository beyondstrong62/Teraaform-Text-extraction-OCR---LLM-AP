# -*- coding: utf-8 -*-
"""Python OCR Engine

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mQJDvzxSu1M8S5NpgX6HSWYKk5W6Ivrw
"""

import base64
import json
import requests
import os
from PIL import Image
import pytesseract

# --- Configuration ---
# IMPORTANT: Replace with your actual Gemini API Key.
# You can get one from Google AI Studio: https://aistudio.google.com/app/apikey
GEMINI_API_KEY = "AIzaSyBZ-4-WkMXzL8LFOB5wjZSDIrSy1bDz7_A" # Your Gemini API key goes here

# Path to the Tesseract executable (e.g., 'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' on Windows)
# If tesseract is in your PATH, you might not need this line.
# pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract' # Example for macOS/Linux
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe' # Example for Windows

# --- Function to encode image to base64 ---
def image_to_base64(image_path):
    """Encodes an image file to a base64 string."""
    try:
        with open(image_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
        return encoded_string
    except FileNotFoundError:
        print(f"Error: Image file not found at {image_path}")
        return None
    except Exception as e:
        print(f"Error encoding image: {e}")
        return None

# --- Function to perform OCR using Gemini API ---
def perform_gemini_ocr(image_path):
    """
    Performs OCR and structured data extraction using the Gemini 2.0 Flash API.
    Args:
        image_path (str): The path to the input image file.
    Returns:
        dict: A dictionary containing the structured output from the LLM, or None if an error occurs.
    """
    base64_image = image_to_base64(image_path)
    if not base64_image:
        return None

    # Determine MIME type based on file extension
    mime_type = "image/jpeg"
    if image_path.lower().endswith(".png"):
        mime_type = "image/png"
    elif image_path.lower().endswith(".webp"):
        mime_type = "image/webp"

    # Define the prompt for the LLM
    prompt = """Analyze the following image.
    1. Identify the type of document: Is it a resume, an Aadhar card, a handwritten note, or something else?
    2. Extract all relevant information from the document.
    3. Provide the output in a structured JSON format.

    For a resume, extract: name, contact (phone/email), education (degrees, institutions, years), experience (job titles, companies, dates, responsibilities).
    For an Aadhar card, extract: name, date of birth, gender, Aadhar number, address.
    For a handwritten document, extract the complete transcribed text.
    For any other document, extract the main text content.

    The JSON should have a 'documentType' field (e.g., "resume", "aadhar", "handwritten", "other") and a 'data' object containing the extracted fields. If it's handwritten, put the transcribed text in a 'extractedText' field within the 'data' object.
    """

    # Define the API endpoint
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"

    # Define the payload with image data and generation config
    payload = {
        "contents": [
            {
                "role": "user",
                "parts": [
                    {"text": prompt},
                    {
                        "inlineData": {
                            "mimeType": mime_type,
                            "data": base64_image
                        }
                    }
                ]
            }
        ],
        "generationConfig": {
            "responseMimeType": "application/json",
            "responseSchema": {
                "type": "OBJECT",
                "properties": {
                    "documentType": {
                        "type": "STRING",
                        "enum": ["resume", "aadhar", "handwritten", "other", "unknown"]
                    },
                    "data": {
                        "type": "OBJECT",
                        "properties": {
                            "name": {"type": "STRING"},
                            "dob": {"type": "STRING"},
                            "gender": {"type": "STRING"},
                            "address": {"type": "STRING"},
                            "idNumber": {"type": "STRING"}, # For Aadhar
                            "contact": {"type": "STRING"}, # For Resume
                            "email": {"type": "STRING"}, # For Resume
                            "education": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "experience": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "extractedText": {"type": "STRING"} # For handwritten or general text
                        },
                        "additionalProperties": True # Allow other properties if LLM adds them
                    },
                    "rawText": {"type": "STRING"} # Optional: to capture raw text if LLM provides it
                },
                "required": ["documentType", "data"]
            }
        }
    }

    headers = {
        "Content-Type": "application/json"
    }

    print("Sending request to Gemini API...")
    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(payload))
        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)
        result = response.json()

        if result.get("candidates") and len(result["candidates"]) > 0 and \
           result["candidates"][0].get("content") and result["candidates"][0]["content"].get("parts") and \
           len(result["candidates"][0]["content"]["parts"]) > 0:
            json_string = result["candidates"][0]["content"]["parts"][0]["text"]
            try:
                parsed_json = json.loads(json_string)
                return parsed_json
            except json.JSONDecodeError:
                print(f"Error: Failed to parse LLM response as JSON. Raw response: {json_string}")
                return None
        else:
            print(f"Error: No valid response from AI. Response: {result}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"An error occurred during API call: {e}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None

# --- Main execution block ---
if __name__ == "__main__":
    # --- Example Usage ---
    # IMPORTANT: Replace 'path/to/your/image.jpg' with the actual path to your image file.
    # You can test with a resume, Aadhar card, or a handwritten note.
    image_file_path = "path/to/your/document.jpg" # <--- CHANGE THIS

    if not os.path.exists(image_file_path):
        print(f"Error: The specified image file '{image_file_path}' does not exist.")
        print("Please update 'image_file_path' in the script to a valid image file on your system.")
    else:
        print(f"Processing image: {image_file_path}")
        structured_data = perform_gemini_ocr(image_file_path)

        if structured_data:
            print("\n--- Structured Output ---")
            print(json.dumps(structured_data, indent=2))
        else:
            print("\nFailed to extract structured data.")

    # --- Optional: Local Tesseract OCR (without Gemini's understanding) ---
    # This part is just for demonstrating basic local OCR if you want to see raw text.
    # It does NOT provide structured output like the Gemini API call above.
    # try:
    #     print("\n--- Raw text from local Tesseract OCR (for comparison) ---")
    #     raw_text = pytesseract.image_to_string(Image.open(image_file_path))
    #     print(raw_text)
    # except pytesseract.TesseractNotFoundError:
    #     print("\nWarning: Tesseract OCR engine not found. Install it to use local OCR.")
    #     print("See: https://tesseract-ocr.github.io/tessdoc/Installation.html")
    # except Exception as e:
    #     print(f"\nError during local Tesseract OCR: {e}")

!sudo apt-get install tesseract-ocr -y
!pip install pytesseract

import base64
import json
import requests
import os
from PIL import Image
import pytesseract

# --- Configuration ---
# IMPORTANT: Replace with your actual Gemini API Key.
# You can get one from Google AI Studio: https://aistudio.google.com/app/apikey
GEMINI_API_KEY = "AIzaSyBZ-4-WkMXzL8LFOB5wjZSDIrSy1bDz7_A" # Your Gemini API key goes here

# Path to the Tesseract executable (e.g., 'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' on Windows)
# If tesseract is in your PATH, you might not need this line.
# pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract' # Example for macOS/Linux
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe' # Example for Windows

# --- Function to encode image to base64 ---
def image_to_base64(image_path):
    """Encodes an image file to a base64 string."""
    try:
        with open(image_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
        return encoded_string
    except FileNotFoundError:
        print(f"Error: Image file not found at {image_path}")
        return None
    except Exception as e:
        print(f"Error encoding image: {e}")
        return None

# --- Function to perform OCR using Gemini API ---
def perform_gemini_ocr(image_path):
    """
    Performs OCR and structured data extraction using the Gemini 2.0 Flash API.
    Args:
        image_path (str): The path to the input image file.
    Returns:
        dict: A dictionary containing the structured output from the LLM, or None if an error occurs.
    """
    base64_image = image_to_base64(image_path)
    if not base64_image:
        return None

    # Determine MIME type based on file extension
    mime_type = "image/jpeg"
    if image_path.lower().endswith(".png"):
        mime_type = "image/png"
    elif image_path.lower().endswith(".webp"):
        mime_type = "image/webp"

    # Define the prompt for the LLM
    prompt = """Analyze the following image.
    1. Identify the type of document: Is it a resume, an Aadhar card, a handwritten note, or something else?
    2. Extract all relevant information from the document.
    3. Provide the output in a structured JSON format.

    For a resume, extract: name, contact (phone/email), education (degrees, institutions, years), experience (job titles, companies, dates, responsibilities).
    For an Aadhar card, extract: name, date of birth, gender, Aadhar number, address.
    For a handwritten document, extract the complete transcribed text.
    For any other document, extract the main text content.

    The JSON should have a 'documentType' field (e.g., "resume", "aadhar", "handwritten", "other") and a 'data' object containing the extracted fields. If it's handwritten, put the transcribed text in a 'extractedText' field within the 'data' object.
    """

    # Define the API endpoint
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"

    # Define the payload with image data and generation config
    payload = {
        "contents": [
            {
                "role": "user",
                "parts": [
                    {"text": prompt},
                    {
                        "inlineData": {
                            "mimeType": mime_type,
                            "data": base64_image
                        }
                    }
                ]
            }
        ],
        "generationConfig": {
            "responseMimeType": "application/json",
            "responseSchema": {
                "type": "OBJECT",
                "properties": {
                    "documentType": {
                        "type": "STRING",
                        "enum": ["resume", "aadhar", "handwritten", "other", "unknown"]
                    },
                    "data": {
                        "type": "OBJECT",
                        "properties": {
                            "name": {"type": "STRING"},
                            "dob": {"type": "STRING"},
                            "gender": {"type": "STRING"},
                            "address": {"type": "STRING"},
                            "idNumber": {"type": "STRING"}, # For Aadhar
                            "contact": {"type": "STRING"}, # For Resume
                            "email": {"type": "STRING"}, # For Resume
                            "education": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "experience": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "extractedText": {"type": "STRING"} # For handwritten or general text
                        },
                        "additionalProperties": True # Allow other properties if LLM adds them
                    },
                    "rawText": {"type": "STRING"} # Optional: to capture raw text if LLM provides it
                },
                "required": ["documentType", "data"]
            }
        }
    }

    headers = {
        "Content-Type": "application/json"
    }

    print("Sending request to Gemini API...")
    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(payload))
        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)
        result = response.json()

        if result.get("candidates") and len(result["candidates"]) > 0 and \
           result["candidates"][0].get("content") and result["candidates"][0]["content"].get("parts") and \
           len(result["candidates"][0]["content"]["parts"]) > 0:
            json_string = result["candidates"][0]["content"]["parts"][0]["text"]
            try:
                parsed_json = json.loads(json_string)
                return parsed_json
            except json.JSONDecodeError:
                print(f"Error: Failed to parse LLM response as JSON. Raw response: {json_string}")
                return None
        else:
            print(f"Error: No valid response from AI. Response: {result}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"An error occurred during API call: {e}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None

# --- Main execution block ---
if __name__ == "__main__":
    # --- Example Usage ---
    # IMPORTANT: Replace 'path/to/your/image.jpg' with the actual path to your image file.
    # You can test with a resume, Aadhar card, or a handwritten note.
    image_file_path = "/content/sh adhar.jpg" # <--- CHANGE THIS

    if not os.path.exists(image_file_path):
        print(f"Error: The specified image file '{image_file_path}' does not exist.")
        print("Please update 'image_file_path' in the script to a valid image file on your system.")
    else:
        print(f"Processing image: {image_file_path}")
        structured_data = perform_gemini_ocr(image_file_path)

        if structured_data:
            print("\n--- Structured Output ---")
            print(json.dumps(structured_data, indent=2))
        else:
            print("\nFailed to extract structured data.")

    # --- Optional: Local Tesseract OCR (without Gemini's understanding) ---
    # This part is just for demonstrating basic local OCR if you want to see raw text.
    # It does NOT provide structured output like the Gemini API call above.
    # try:
    #     print("\n--- Raw text from local Tesseract OCR (for comparison) ---")
    #     raw_text = pytesseract.image_to_string(Image.open(image_file_path))
    #     print(raw_text)
    # except pytesseract.TesseractNotFoundError:
    #     print("\nWarning: Tesseract OCR engine not found. Install it to use local OCR.")
    #     print("See: https://tesseract-ocr.github.io/tessdoc/Installation.html")
    # except Exception as e:
    #     print(f"\nError during local Tesseract OCR: {e}")

import base64
import json
import requests
import os
from PIL import Image
import pytesseract
import mimetypes # Import mimetypes module

# --- Configuration ---
# IMPORTANT: Replace with your actual Gemini API Key.
# You can get one from Google AI Studio: https://aistudio.google.com/app/apikey
GEMINI_API_KEY = "AIzaSyBZ-4-WkMXzL8LFOB5wjZSDIrSy1bDz7_A" # Your Gemini API key goes here

# Path to the Tesseract executable (e.g., 'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' on Windows)
# If tesseract is in your PATH, you might not need this line.
# pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract' # Example for macOS/Linux
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe' # Example for Windows

# --- Function to encode image to base64 ---
def image_to_base64(image_path):
    """Encodes an image file to a base64 string."""
    try:
        with open(image_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
        return encoded_string
    except FileNotFoundError:
        print(f"Error: Image file not found at {image_path}")
        return None
    except Exception as e:
        print(f"Error encoding image: {e}")
        return None

# --- Function to perform OCR using Gemini API ---
def perform_gemini_ocr(image_path):
    """
    Performs OCR and structured data extraction using the Gemini 2.0 Flash API.
    Args:
        image_path (str): The path to the input image file.
    Returns:
        dict: A dictionary containing the structured output from the LLM, or None if an error occurs.
    """
    if not GEMINI_API_KEY:
        print("Error: GEMINI_API_KEY is not set. Please provide your API key.")
        return None

    base64_image = image_to_base64(image_path)
    if not base64_image:
        return None

    # Determine MIME type using mimetypes module for better accuracy
    mime_type, _ = mimetypes.guess_type(image_path)
    if not mime_type or not mime_type.startswith('image/'):
        print(f"Warning: Could not determine valid image MIME type for {image_path}. Defaulting to image/jpeg.")
        mime_type = "image/jpeg" # Fallback

    print(f"Detected MIME type: {mime_type}")
    print(f"Base64 image data length: {len(base64_image)} characters") # Debug print

    # Define the prompt for the LLM
    prompt = """Analyze the following image.
    1. Identify the type of document: Is it a resume, an Aadhar card, a handwritten note, or something else?
    2. Extract all relevant information from the document.
    3. Provide the output in a structured JSON format.

    For a resume, extract: name, contact (phone/email), education (degrees, institutions, years), experience (job titles, companies, dates, responsibilities).
    For an Aadhar card, extract: name, date of birth, gender, Aadhar number, address.
    For a handwritten document, extract the complete transcribed text.
    For any other document, extract the main text content.

    The JSON should have a 'documentType' field (e.g., "resume", "aadhar", "handwritten", "other") and a 'data' object containing the extracted fields. If it's handwritten, put the transcribed text in a 'extractedText' field within the 'data' object.
    """

    # Define the API endpoint
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"

    # Define the payload with image data and generation config
    payload = {
        "contents": [
            {
                "role": "user",
                "parts": [
                    {"text": prompt},
                    {
                        "inlineData": {
                            "mimeType": mime_type,
                            "data": base64_image
                        }
                    }
                ]
            }
        ],
        "generationConfig": {
            "responseMimeType": "application/json",
            "responseSchema": {
                "type": "OBJECT",
                "properties": {
                    "documentType": {
                        "type": "STRING",
                        "enum": ["resume", "aadhar", "handwritten", "other", "unknown"]
                    },
                    "data": {
                        "type": "OBJECT",
                        "properties": {
                            "name": {"type": "STRING"},
                            "dob": {"type": "STRING"},
                            "gender": {"type": "STRING"},
                            "address": {"type": "STRING"},
                            "idNumber": {"type": "STRING"}, # For Aadhar
                            "contact": {"type": "STRING"}, # For Resume
                            "email": {"type": "STRING"}, # For Resume
                            "education": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "experience": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "extractedText": {"type": "STRING"} # For handwritten or general text
                        },
                        "additionalProperties": True # Allow other properties if LLM adds them
                    },
                    "rawText": {"type": "STRING"} # Optional: to capture raw text if LLM provides it
                },
                "required": ["documentType", "data"]
            }
        }
    }

    headers = {
        "Content-Type": "application/json"
    }

    print("Sending request to Gemini API...")
    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(payload))
        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)
        result = response.json()

        if result.get("candidates") and len(result["candidates"]) > 0 and \
           result["candidates"][0].get("content") and result["candidates"][0]["content"].get("parts") and \
           len(result["candidates"][0]["content"]["parts"]) > 0:
            json_string = result["candidates"][0]["content"]["parts"][0]["text"]
            try:
                parsed_json = json.loads(json_string)
                return parsed_json
            except json.JSONDecodeError:
                print(f"Error: Failed to parse LLM response as JSON. Raw response: {json_string}")
                return None
        else:
            print(f"Error: No valid response from AI. Response: {result}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"An error occurred during API call: {e}")
        # Print the response content for more details on the 400 error
        if response is not None:
            print(f"API Response Content: {response.text}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None

# --- Main execution block ---
if __name__ == "__main__":
    # --- Example Usage ---
    # IMPORTANT: Replace 'path/to/your/image.jpg' with the actual path to your image file.
    # You can test with a resume, Aadhar card, or a handwritten note.
    image_file_path = r"/content/sh adhar.jpg" # <--- This is the line to change

    if not os.path.exists(image_file_path):
        print(f"Error: The specified image file '{image_file_path}' does not exist.")
        print("Please update 'image_file_path' in the script to a valid image file on your system.")
    else:
        print(f"Processing image: {image_file_path}")
        structured_data = perform_gemini_ocr(image_file_path)

        if structured_data:
            print("\n--- Structured Output ---")
            print(json.dumps(structured_data, indent=2))
        else:
            print("\nFailed to extract structured data.")

    # --- Optional: Local Tesseract OCR (without Gemini's understanding) ---
    # This part is just for demonstrating basic local OCR if you want to see raw text.
    # It does NOT provide structured output like the Gemini API call above.
    # try:
    #     print("\n--- Raw text from local Tesseract OCR (for comparison) ---")
    #     raw_text = pytesseract.image_to_string(Image.open(image_file_path))
    #     print(raw_text)
    # except pytesseract.TesseractNotFoundError:
    #     print("\nWarning: Tesseract OCR engine not found. Install it to use local OCR.")
    #     print("See: https://tesseract-ocr.github.io/tessdoc/Installation.html")
    # except Exception as e:
    #     print(f"\nError during local Tesseract OCR: {e}")

import base64
import json
import requests
import os
from PIL import Image
import pytesseract
import mimetypes # Import mimetypes module

# --- Configuration ---
# IMPORTANT: Replace with your actual Gemini API Key.
# You can get one from Google AI Studio: https://aistudio.google.com/app/apikey
GEMINI_API_KEY = "AIzaSyCmw6bXu01lQCM61V3LLGC8x1Rzgwn1bgw" # Your Gemini API key goes here

# Path to the Tesseract executable (e.g., 'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' on Windows)
# If tesseract is in your PATH, you might not need this line.
# pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract' # Example for macOS/Linux
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe' # Example for Windows

# --- Function to encode image to base64 ---
def image_to_base64(image_path):
    """Encodes an image file to a base64 string."""
    try:
        with open(image_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
        return encoded_string
    except FileNotFoundError:
        print(f"Error: Image file not found at {image_path}")
        return None
    except Exception as e:
        print(f"Error encoding image: {e}")
        return None

# --- Function to perform OCR using Gemini API ---
def perform_gemini_ocr(image_path):
    """
    Performs OCR and structured data extraction using the Gemini 2.0 Flash API.
    Args:
        image_path (str): The path to the input image file.
    Returns:
        dict: A dictionary containing the structured output from the LLM, or None if an error occurs.
    """
    if not GEMINI_API_KEY:
        print("Error: GEMINI_API_KEY is not set. Please provide your API key.")
        return None

    base64_image = image_to_base64(image_path)
    if not base64_image:
        return None

    # Determine MIME type using mimetypes module for better accuracy
    mime_type, _ = mimetypes.guess_type(image_path)
    if not mime_type or not mime_type.startswith('image/'):
        print(f"Warning: Could not determine valid image MIME type for {image_path}. Defaulting to image/jpeg.")
        mime_type = "image/jpeg" # Fallback

    print(f"Detected MIME type: {mime_type}")
    print(f"Base64 image data length: {len(base64_image)} characters") # Debug print

    # Define the prompt for the LLM
    prompt = """Analyze the following image.
    1. Identify the type of document: Is it a resume, an Aadhar card, a handwritten note, or something else?
    2. Extract all relevant information from the document.
    3. Provide the output in a structured JSON format.

    For a resume, extract: name, contact (phone/email), education (degrees, institutions, years), experience (job titles, companies, dates, responsibilities).
    For an Aadhar card, extract: name, date of birth, gender, Aadhar number, address.
    For a handwritten document, extract the complete transcribed text.
    For any other document, extract the main text content.

    The JSON should have a 'documentType' field (e.g., "resume", "aadhar", "handwritten", "other") and a 'data' object containing the extracted fields. If it's handwritten, put the transcribed text in a 'extractedText' field within the 'data' object.
    """

    # Define the API endpoint
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"

    # Define the payload with image data and generation config
    payload = {
        "contents": [
            {
                "role": "user",
                "parts": [
                    {"text": prompt},
                    {
                        "inlineData": {
                            "mimeType": mime_type,
                            "data": base64_image
                        }
                    }
                ]
            }
        ],
        "generationConfig": {
            "responseMimeType": "application/json",
            "responseSchema": {
                "type": "OBJECT",
                "properties": {
                    "documentType": {
                        "type": "STRING",
                        "enum": ["resume", "aadhar", "handwritten", "other", "unknown"]
                    },
                    "data": {
                        "type": "OBJECT",
                        "properties": {
                            "name": {"type": "STRING"},
                            "dob": {"type": "STRING"},
                            "gender": {"type": "STRING"},
                            "address": {"type": "STRING"},
                            "idNumber": {"type": "STRING"}, # For Aadhar
                            "contact": {"type": "STRING"}, # For Resume
                            "email": {"type": "STRING"}, # For Resume
                            "education": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "experience": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "extractedText": {"type": "STRING"} # For handwritten or general text
                        },
                        # Removed "additionalProperties": True as it caused a Bad Request error
                    },
                    "rawText": {"type": "STRING"} # Optional: to capture raw text if LLM provides it
                },
                "required": ["documentType", "data"]
            }
        }
    }

    headers = {
        "Content-Type": "application/json"
    }

    print("Sending request to Gemini API...")
    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(payload))
        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)
        result = response.json()

        if result.get("candidates") and len(result["candidates"]) > 0 and \
           result["candidates"][0].get("content") and result["candidates"][0]["content"].get("parts") and \
           len(result["candidates"][0]["content"]["parts"]) > 0:
            json_string = result["candidates"][0]["content"]["parts"][0]["text"]
            try:
                parsed_json = json.loads(json_string)
                return parsed_json
            except json.JSONDecodeError:
                print(f"Error: Failed to parse LLM response as JSON. Raw response: {json_string}")
                return None
        else:
            print(f"Error: No valid response from AI. Response: {result}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"An error occurred during API call: {e}")
        # Print the response content for more details on the 400 error
        if response is not None:
            print(f"API Response Content: {response.text}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None

# --- Main execution block ---
if __name__ == "__main__":
    # --- Example Usage ---
    # IMPORTANT: Replace 'path/to/your/image.jpg' with the actual path to your image file.
    # You can test with a resume, Aadhar card, or a handwritten note.
    image_file_path = "/content/sh adhar.jpg" # <--- This is the line to change

    if not os.path.exists(image_file_path):
        print(f"Error: The specified image file '{image_file_path}' does not exist.")
        print("Please update 'image_file_path' in the script to a valid image file on your system.")
    else:
        print(f"Processing image: {image_file_path}")
        structured_data = perform_gemini_ocr(image_file_path)

        if structured_data:
            print("\n--- Structured Output ---")
            print(json.dumps(structured_data, indent=2))
        else:
            print("\nFailed to extract structured data.")

    # --- Optional: Local Tesseract OCR (without Gemini's understanding) ---
    # This part is just for demonstrating basic local OCR if you want to see raw text.
    # It does NOT provide structured output like the Gemini API call above.
    # try:
    #     print("\n--- Raw text from local Tesseract OCR (for comparison) ---")
    #     raw_text = pytesseract.image_to_string(Image.open(image_file_path))
    #     print(raw_text)
    # except pytesseract.TesseractNotFoundError:
    #     print("\nWarning: Tesseract OCR engine not found. Install it to use local OCR.")
    #     print("See: https://tesseract-ocr.github.io/tessdoc/Installation.html")
    # except Exception as e:
    #     print(f"\nError during local Tesseract OCR: {e}")

import base64
import json
import requests
import os
from PIL import Image
import pytesseract
import mimetypes # Import mimetypes module

# --- Configuration ---
# IMPORTANT: Replace with your actual Gemini API Key.
# You can get one from Google AI Studio: https://aistudio.google.com/app/apikey
GEMINI_API_KEY = "AIzaSyCmw6bXu01lQCM61V3LLGC8x1Rzgwn1bgw" # Your Gemini API key goes here

# Path to the Tesseract executable (e.g., 'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' on Windows)
# If tesseract is in your PATH, you might not need this line.
# pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract' # Example for macOS/Linux
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe' # Example for Windows

# --- Function to encode image to base64 ---
def image_to_base64(image_path):
    """Encodes an image file to a base64 string."""
    try:
        with open(image_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
        return encoded_string
    except FileNotFoundError:
        print(f"Error: Image file not found at {image_path}")
        return None
    except Exception as e:
        print(f"Error encoding image: {e}")
        return None

# --- Function to perform OCR using Gemini API ---
def perform_gemini_ocr(image_path):
    """
    Performs OCR and structured data extraction using the Gemini 2.0 Flash API.
    Args:
        image_path (str): The path to the input image file.
    Returns:
        dict: A dictionary containing the structured output from the LLM, or None if an error occurs.
    """
    if not GEMINI_API_KEY:
        print("Error: GEMINI_API_KEY is not set. Please provide your API key.")
        return None

    base64_image = image_to_base64(image_path)
    if not base64_image:
        return None

    # Determine MIME type using mimetypes module for better accuracy
    mime_type, _ = mimetypes.guess_type(image_path)
    if not mime_type or not mime_type.startswith('image/'):
        print(f"Warning: Could not determine valid image MIME type for {image_path}. Defaulting to image/jpeg.")
        mime_type = "image/jpeg" # Fallback

    print(f"Detected MIME type: {mime_type}")
    print(f"Base64 image data length: {len(base64_image)} characters") # Debug print

    # Define the prompt for the LLM
    prompt = """Analyze the following image.
    1. Identify the type of document: Is it a resume, an Aadhar card, a handwritten note, or something else?
    2. Extract all relevant information from the document.
    3. Provide the output in a structured JSON format.

    For a resume, extract: name, contact (phone/email), education (degrees, institutions, years), experience (job titles, companies, dates, responsibilities).
    For an Aadhar card, extract: name (single instance, prefer English if available, otherwise primary language), father's name (single instance, prefer English if available, otherwise primary language), date of birth, gender, Aadhar number, address.
    For a handwritten document, extract the complete transcribed text.
    For any other document, extract the main text content.

    The JSON should have a 'documentType' field (e.g., "resume", "aadhar", "handwritten", "other") and a 'data' object containing the extracted fields. If it's handwritten, put the transcribed text in a 'extractedText' field within the 'data' object.
    """

    # Define the API endpoint
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"

    # Define the payload with image data and generation config
    payload = {
        "contents": [
            {
                "role": "user",
                "parts": [
                    {"text": prompt},
                    {
                        "inlineData": {
                            "mimeType": mime_type,
                            "data": base64_image
                        }
                    }
                ]
            }
        ],
        "generationConfig": {
            "responseMimeType": "application/json",
            "responseSchema": {
                "type": "OBJECT",
                "properties": {
                    "documentType": {
                        "type": "STRING",
                        "enum": ["resume", "aadhar", "handwritten", "other", "unknown"]
                    },
                    "data": {
                        "type": "OBJECT",
                        "properties": {
                            "name": {"type": "STRING"},
                            "fatherName": {"type": "STRING"}, # Added fatherName field
                            "dob": {"type": "STRING"},
                            "gender": {"type": "STRING"},
                            "address": {"type": "STRING"},
                            "idNumber": {"type": "STRING"}, # For Aadhar
                            "contact": {"type": "STRING"}, # For Resume
                            "email": {"type": "STRING"}, # For Resume
                            "education": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "experience": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "extractedText": {"type": "STRING"} # For handwritten or general text
                        },
                    },
                    "rawText": {"type": "STRING"} # Optional: to capture raw text if LLM provides it
                },
                "required": ["documentType", "data"]
            }
        }
    }

    headers = {
        "Content-Type": "application/json"
    }

    print("Sending request to Gemini API...")
    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(payload))
        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)
        result = response.json()

        if result.get("candidates") and len(result["candidates"]) > 0 and \
           result["candidates"][0].get("content") and result["candidates"][0]["content"].get("parts") and \
           len(result["candidates"][0]["content"]["parts"]) > 0:
            json_string = result["candidates"][0]["content"]["parts"][0]["text"]
            try:
                parsed_json = json.loads(json_string)
                return parsed_json
            except json.JSONDecodeError:
                print(f"Error: Failed to parse LLM response as JSON. Raw response: {json_string}")
                return None
        else:
            print(f"Error: No valid response from AI. Response: {result}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"An error occurred during API call: {e}")
        # Print the response content for more details on the 400 error
        if response is not None:
            print(f"API Response Content: {response.text}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None

# --- Main execution block ---
if __name__ == "__main__":
    # --- Example Usage ---
    # IMPORTANT: Replace 'path/to/your/image.jpg' with the actual path to your image file.
    # You can test with a resume, Aadhar card, or a handwritten note.
    image_file_path = "/content/sh adhar.jpg" # <--- This is the line to change

    if not os.path.exists(image_file_path):
        print(f"Error: The specified image file '{image_file_path}' does not exist.")
        print("Please update 'image_file_path' in the script to a valid image file on your system.")
    else:
        print(f"Processing image: {image_file_path}")
        structured_data = perform_gemini_ocr(image_file_path)

        if structured_data:
            print("\n--- Structured Output ---")
            print(json.dumps(structured_data, indent=2))
        else:
            print("\nFailed to extract structured data.")

    # --- Optional: Local Tesseract OCR (without Gemini's understanding) ---
    # This part is just for demonstrating basic local OCR if you want to see raw text.
    # It does NOT provide structured output like the Gemini API call above.
    # try:
    #     print("\n--- Raw text from local Tesseract OCR (for comparison) ---")
    #     raw_text = pytesseract.image_to_string(Image.open(image_file_path))
    #     print(raw_text)
    # except pytesseract.TesseractNotFoundError:
    #     print("\nWarning: Tesseract OCR engine not found. Install it to use local OCR.")
    #     print("See: https://tesseract-ocr.github.io/tessdoc/Installation.html")
    # except Exception as e:
    #     print(f"\nError during local Tesseract OCR: {e}")

import base64
import json
import requests
import os
from PIL import Image
import pytesseract
import mimetypes # Import mimetypes module
import re # Import regex module for cleaning

# --- Configuration ---
# IMPORTANT: Replace with your actual Gemini API Key.
# You can get one from Google AI Studio: https://aistudio.google.com/app/apikey
GEMINI_API_KEY = "AIzaSyCmw6bXu01lQCM61V3LLGC8x1Rzgwn1bgw" # Your Gemini API key goes here

# Path to the Tesseract executable (e.g., 'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' on Windows)
# If tesseract is in your PATH, you might not need this line.
# pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract' # Example for macOS/Linux
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe' # Example for Windows

# --- Function to encode image to base64 ---
def image_to_base64(image_path):
    """Encodes an image file to a base64 string."""
    try:
        with open(image_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
        return encoded_string
    except FileNotFoundError:
        print(f"Error: Image file not found at {image_path}")
        return None
    except Exception as e:
        print(f"Error encoding image: {e}")
        return None

# --- Post-processing function for Aadhar data ---
def _post_process_aadhar_data(data):
    """
    Cleans and deduplicates name and father's name fields for Aadhar documents.
    Prioritizes English names if multiple languages are present.
    """
    if data.get("documentType") == "aadhar" and "data" in data:
        extracted_data = data["data"]

        def clean_and_deduplicate_name(text_field):
            if not isinstance(text_field, str):
                return text_field # Return as is if not a string

            # Split by newlines and filter out empty strings
            lines = [line.strip() for line in text_field.split('\n') if line.strip()]

            # Remove common Aadhar specific repetitions or prefixes like "S/O"
            cleaned_lines = []
            for line in lines:
                # This regex targets "S/O" followed by words (case-insensitive)
                cleaned_line = re.sub(r'S/O\s+[\w\s]+', '', line, flags=re.IGNORECASE).strip()
                # Remove "1, 1," or similar artifacts
                cleaned_line = re.sub(r',\s*\d+,\s*\d+', '', cleaned_line).strip()
                if cleaned_line: # Only add if not empty after cleaning
                    cleaned_lines.append(cleaned_line)

            # Get unique lines while preserving order
            unique_lines = []
            seen = set()
            for line in cleaned_lines:
                if line not in seen:
                    unique_lines.append(line)
                    seen.add(line)

            # Heuristic to prioritize English-like names
            english_names = [line for line in unique_lines if all(ord(char) < 128 for char in line)] # Check for ASCII characters

            if english_names:
                # If multiple English names, pick the first one that looks like a full name
                # (e.g., contains a space, not just initials)
                for name in english_names:
                    if ' ' in name and len(name.split()) > 1: # Simple check for full name
                        return name
                return english_names[0] # Fallback to first English name if no full name found

            if unique_lines:
                # If no clear English name, return the first unique line
                return unique_lines[0]

            return "" # Return empty string if nothing found

        if "name" in extracted_data:
            extracted_data["name"] = clean_and_deduplicate_name(extracted_data["name"])
        if "fatherName" in extracted_data:
            extracted_data["fatherName"] = clean_and_deduplicate_name(extracted_data["fatherName"])

    return data


# --- Function to perform OCR using Gemini API ---
def perform_gemini_ocr(image_path):
    """
    Performs OCR and structured data extraction using the Gemini 2.0 Flash API.
    Args:
        image_path (str): The path to the input image file.
    Returns:
        dict: A dictionary containing the structured output from the LLM, or None if an error occurs.
    """
    if not GEMINI_API_KEY:
        print("Error: GEMINI_API_KEY is not set. Please provide your API key.")
        return None

    base64_image = image_to_base64(image_path)
    if not base64_image:
        return None

    # Determine MIME type using mimetypes module for better accuracy
    mime_type, _ = mimetypes.guess_type(image_path)
    if not mime_type or not mime_type.startswith('image/'):
        print(f"Warning: Could not determine valid image MIME type for {image_path}. Defaulting to image/jpeg.")
        mime_type = "image/jpeg" # Fallback

    print(f"Detected MIME type: {mime_type}")
    print(f"Base64 image data length: {len(base64_image)} characters") # Debug print

    # Define the prompt for the LLM - UPDATED FOR DEDUPLICATION AND SPECIFIC FIELDS
    prompt = """Analyze the following image.
    1. Identify the type of document: Is it a resume, an Aadhar card, a handwritten note, or something else?
    2. Extract all relevant information from the document.
    3. Provide the output in a structured JSON format.

    For a resume, extract: name, phoneNumber, email, education (degrees, institutions, years), experience (job titles, companies, dates, responsibilities).
    For an Aadhar card, extract:
        - name: Provide the full name. If multiple languages are present, try to provide both, but ensure each is a single instance.
        - father's name: Provide the full father's name. If multiple languages are present, try to provide both, but ensure each is a single instance.
        - date of birth
        - gender
        - Aadhar number
        - address
    For a handwritten document, extract the complete transcribed text.
    For any other document, extract the main text content.

    The JSON should have a 'documentType' field (e.g., "resume", "aadhar", "handwritten", "other") and a 'data' object containing the extracted fields. If it's handwritten, put the transcribed text in a 'extractedText' field within the 'data' object.
    """

    # Define the API endpoint
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"

    # Define the payload with image data and generation config - UPDATED SCHEMA
    payload = {
        "contents": [
            {
                "role": "user",
                "parts": [
                    {"text": prompt},
                    {
                        "inlineData": {
                            "mimeType": mime_type,
                            "data": base64_image
                        }
                    }
                ]
            }
        ],
        "generationConfig": {
            "responseMimeType": "application/json",
            "responseSchema": {
                "type": "OBJECT",
                "properties": {
                    "documentType": {
                        "type": "STRING",
                        "enum": ["resume", "aadhar", "handwritten", "other", "unknown"]
                    },
                    "data": {
                        "type": "OBJECT",
                        "properties": {
                            "name": {"type": "STRING"},
                            "fatherName": {"type": "STRING"}, # Added fatherName field
                            "dob": {"type": "STRING"},
                            "gender": {"type": "STRING"},
                            "address": {"type": "STRING"},
                            "idNumber": {"type": "STRING"}, # For Aadhar
                            "phoneNumber": {"type": "STRING"}, # Changed from 'contact' for resume
                            "email": {"type": "STRING"},     # Changed from 'contact' for resume
                            "education": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "experience": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "extractedText": {"type": "STRING"} # For handwritten or general text
                        },
                    },
                    "rawText": {"type": "STRING"} # Optional: to capture raw text if LLM provides it
                },
                "required": ["documentType", "data"]
            }
        }
    }

    headers = {
        "Content-Type": "application/json"
    }

    print("Sending request to Gemini API...")
    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(payload))
        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)
        result = response.json()

        if result.get("candidates") and len(result["candidates"]) > 0 and \
           result["candidates"][0].get("content") and result["candidates"][0]["content"].get("parts") and \
           len(result["candidates"][0]["content"]["parts"]) > 0:
            json_string = result["candidates"][0]["content"]["parts"][0]["text"]
            try:
                parsed_json = json.loads(json_string)
                # Apply post-processing here
                processed_json = _post_process_aadhar_data(parsed_json)
                return processed_json
            except json.JSONDecodeError:
                print(f"Error: Failed to parse LLM response as JSON. Raw response: {json_string}")
                return None
        else:
            print(f"Error: No valid response from AI. Response: {result}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"An error occurred during API call: {e}")
        # Print the response content for more details on the 400 error
        if response is not None:
            print(f"API Response Content: {response.text}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None

# --- Main execution block ---
if __name__ == "__main__":
    # --- Example Usage ---
    # IMPORTANT: Replace 'path/to/your/image.jpg' with the actual path to your image file.
    # You can test with a resume, Aadhar card, or a handwritten note.
    image_file_path = "/content/sh adhar.jpg" # <--- This is the line to change

    if not os.path.exists(image_file_path):
        print(f"Error: The specified image file '{image_file_path}' does not exist.")
        print("Please update 'image_file_path' in the script to a valid image file on your system.")
    else:
        print(f"Processing image: {image_file_path}")
        structured_data = perform_gemini_ocr(image_file_path)

        if structured_data:
            print("\n--- Structured Output ---")
            print(json.dumps(structured_data, indent=2)) # Print full JSON for reference

            while True:
                field_to_extract = input("\nEnter the field you want to extract (e.g., name, address, dob, fatherName, idNumber, phoneNumber, email, extractedText, documentType) or type 'exit' to quit: ").strip()
                if field_to_extract.lower() == 'exit':
                    break

                if 'data' in structured_data and field_to_extract in structured_data['data']:
                    print(f"\n--- Extracted {field_to_extract} ---")
                    print(structured_data['data'][field_to_extract])
                elif field_to_extract == 'documentType' and 'documentType' in structured_data:
                    print(f"\n--- Extracted {field_to_extract} ---")
                    print(structured_data['documentType'])
                elif field_to_extract == 'rawText' and 'rawText' in structured_data:
                    print(f"\n--- Extracted {field_to_extract} ---")
                    print(structured_data['rawText'])
                else:
                    print(f"Field '{field_to_extract}' not found in the structured output or is not a top-level field.")
                    print("Available fields in 'data' object: " + ", ".join(structured_data.get('data', {}).keys()))
                    print("Available top-level fields: documentType, rawText")
        else:
            print("\nFailed to extract structured data.")

    # --- Optional: Local Tesseract OCR (without Gemini's understanding) ---
    # This part is just for demonstrating basic local OCR if you want to see raw text.
    # It does NOT provide structured output like the Gemini API call above.
    # try:
    #     print("\n--- Raw text from local Tesseract OCR (for comparison) ---")
    #     raw_text = pytesseract.image_to_string(Image.open(image_file_path))
    #     print(raw_text)
    # except pytesseract.TesseractNotFoundError:
    #     print("\nWarning: Tesseract OCR engine not found. Install it to use local OCR.")
    #     print("See: https://tesseract-ocr.github.io/tessdoc/Installation.html")
    # except Exception as e:
    #     print(f"\nError during local Tesseract OCR: {e}")

import base64
import json
import requests
import os
from PIL import Image
import pytesseract
import mimetypes # Import mimetypes module
import re # Import regex module for cleaning

# --- Configuration ---
# IMPORTANT: Replace with your actual Gemini API Key.
# You can get one from Google AI Studio: https://aistudio.google.com/app/apikey
GEMINI_API_KEY = "AIzaSyCmw6bXu01lQCM61V3LLGC8x1Rzgwn1bgw" # Your Gemini API key goes here

# Path to the Tesseract executable (e.g., 'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' on Windows)
# If tesseract is in your PATH, you might not need this line.
# pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract' # Example for macOS/Linux
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe' # Example for Windows

# --- Function to encode image to base64 ---
def image_to_base64(image_path):
    """Encodes an image file to a base64 string."""
    try:
        with open(image_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
        return encoded_string
    except FileNotFoundError:
        print(f"Error: Image file not found at {image_path}")
        return None
    except Exception as e:
        print(f"Error encoding image: {e}")
        return None

# --- Post-processing function for Aadhar data ---
def _post_process_aadhar_data(data):
    """
    Cleans and deduplicates name and father's name fields for Aadhar documents.
    Prioritizes English names if multiple languages are present.
    """
    if data.get("documentType") == "aadhar" and "data" in data:
        extracted_data = data["data"]

        def clean_and_deduplicate_name(text_field):
            if not isinstance(text_field, str):
                return text_field # Return as is if not a string

            # Split by newlines and filter out empty strings
            lines = [line.strip() for line in text_field.split('\n') if line.strip()]

            # Remove common Aadhar specific repetitions or prefixes like "S/O"
            cleaned_lines = []
            for line in lines:
                # This regex targets "S/O" followed by words (case-insensitive)
                cleaned_line = re.sub(r'S/O\s+[\w\s]+', '', line, flags=re.IGNORECASE).strip()
                # Remove "1, 1," or similar artifacts
                cleaned_line = re.sub(r',\s*\d+,\s*\d+', '', cleaned_line).strip()
                if cleaned_line: # Only add if not empty after cleaning
                    cleaned_lines.append(cleaned_line)

            # Get unique lines while preserving order
            unique_lines = []
            seen = set()
            for line in cleaned_lines:
                if line not in seen:
                    unique_lines.append(line)
                    seen.add(line)

            # Heuristic to prioritize English-like names
            english_names = [line for line in unique_lines if all(ord(char) < 128 for char in line)] # Check for ASCII characters

            if english_names:
                # If multiple English names, pick the first one that looks like a full name
                # (e.g., contains a space, not just initials)
                for name in english_names:
                    if ' ' in name and len(name.split()) > 1: # Simple check for full name
                        return name
                return english_names[0] # Fallback to first English name if no full name found

            if unique_lines:
                # If no clear English name, return the first unique line
                return unique_lines[0]

            return "" # Return empty string if nothing found

        if "name" in extracted_data:
            extracted_data["name"] = clean_and_deduplicate_name(extracted_data["name"])
        if "fatherName" in extracted_data:
            extracted_data["fatherName"] = clean_and_deduplicate_name(extracted_data["fatherName"])

    return data


# --- Function to perform OCR using Gemini API ---
def perform_gemini_ocr(image_path):
    """
    Performs OCR and structured data extraction using the Gemini 2.0 Flash API.
    Args:
        image_path (str): The path to the input image file.
    Returns:
        dict: A dictionary containing the structured output from the LLM, or None if an error occurs.
    """
    if not GEMINI_API_KEY:
        print("Error: GEMINI_API_KEY is not set. Please provide your API key.")
        return None

    base64_image = image_to_base64(image_path)
    if not base64_image:
        return None

    # Determine MIME type using mimetypes module for better accuracy
    mime_type, _ = mimetypes.guess_type(image_path)
    if not mime_type or not mime_type.startswith('image/'):
        print(f"Warning: Could not determine valid image MIME type for {image_path}. Defaulting to image/jpeg.")
        mime_type = "image/jpeg" # Fallback

    print(f"Detected MIME type: {mime_type}")
    print(f"Base64 image data length: {len(base64_image)} characters") # Debug print

    # Define the prompt for the LLM - UPDATED FOR DEDUPLICATION AND SPECIFIC FIELDS
    prompt = """Analyze the following image.
    1. Identify the type of document: Is it a resume, an Aadhar card, a handwritten note, or something else?
    2. Extract all relevant information from the document.
    3. Provide the output in a structured JSON format.

    For a resume, extract: name, phoneNumber, email, education (degrees, institutions, years), experience (job titles, companies, dates, responsibilities).
    For an Aadhar card, extract:
        - name: Provide the full name. If multiple languages are present, try to provide both, but ensure each is a single instance.
        - father's name: Provide the full father's name. If multiple languages are present, try to provide both, but ensure each is a single instance.
        - date of birth
        - gender
        - Aadhar number
        - address
    For a handwritten document, extract the complete transcribed text.
    For any other document, extract the main text content.

    The JSON should have a 'documentType' field (e.g., "resume", "aadhar", "handwritten", "other") and a 'data' object containing the extracted fields. If it's handwritten, put the transcribed text in a 'extractedText' field within the 'data' object.
    """

    # Define the API endpoint
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"

    # Define the payload with image data and generation config - UPDATED SCHEMA
    payload = {
        "contents": [
            {
                "role": "user",
                "parts": [
                    {"text": prompt},
                    {
                        "inlineData": {
                            "mimeType": mime_type,
                            "data": base64_image
                        }
                    }
                ]
            }
        ],
        "generationConfig": {
            "responseMimeType": "application/json",
            "responseSchema": {
                "type": "OBJECT",
                "properties": {
                    "documentType": {
                        "type": "STRING",
                        "enum": ["resume", "aadhar", "handwritten", "other", "unknown"]
                    },
                    "data": {
                        "type": "OBJECT",
                        "properties": {
                            "name": {"type": "STRING"},
                            "fatherName": {"type": "STRING"}, # Added fatherName field
                            "dob": {"type": "STRING"},
                            "gender": {"type": "STRING"},
                            "address": {"type": "STRING"},
                            "idNumber": {"type": "STRING"}, # For Aadhar
                            "phoneNumber": {"type": "STRING"}, # Changed from 'contact' for resume
                            "email": {"type": "STRING"},     # Changed from 'contact' for resume
                            "education": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "experience": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "extractedText": {"type": "STRING"} # For handwritten or general text
                        },
                    },
                    "rawText": {"type": "STRING"} # Optional: to capture raw text if LLM provides it
                },
                "required": ["documentType", "data"]
            }
        }
    }

    headers = {
        "Content-Type": "application/json"
    }

    print("Sending request to Gemini API...")
    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(payload))
        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)
        result = response.json()

        if result.get("candidates") and len(result["candidates"]) > 0 and \
           result["candidates"][0].get("content") and result["candidates"][0]["content"].get("parts") and \
           len(result["candidates"][0]["content"]["parts"]) > 0:
            json_string = result["candidates"][0]["content"]["parts"][0]["text"]
            try:
                parsed_json = json.loads(json_string)
                # Apply post-processing here
                processed_json = _post_process_aadhar_data(parsed_json)
                return processed_json
            except json.JSONDecodeError:
                print(f"Error: Failed to parse LLM response as JSON. Raw response: {json_string}")
                return None
        else:
            print(f"Error: No valid response from AI. Response: {result}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"An error occurred during API call: {e}")
        # Print the response content for more details on the 400 error
        if response is not None:
            print(f"API Response Content: {response.text}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None

# --- Main execution block ---
if __name__ == "__main__":
    # --- Example Usage ---
    # IMPORTANT: Replace 'path/to/your/image.jpg' with the actual path to your image file.
    # You can test with a resume, Aadhar card, or a handwritten note.
    image_file_path = "/content/sh adhar.jpg" # <--- This is the line to change

    if not os.path.exists(image_file_path):
        print(f"Error: The specified image file '{image_file_path}' does not exist.")
        print("Please update 'image_file_path' in the script to a valid image file on your system.")
    else:
        print(f"Processing image: {image_file_path}")
        structured_data = perform_gemini_ocr(image_file_path)

        if structured_data:
            print("\n--- Structured Output ---")
            print(json.dumps(structured_data, indent=2)) # Print full JSON for reference

            while True:
                field_to_extract = input("\nEnter the field you want to extract (e.g., name, address, dob, fatherName, idNumber, phoneNumber, email, extractedText, documentType) or type 'exit' to quit: ").strip()
                if field_to_extract.lower() == 'exit':
                    break

                if 'data' in structured_data and field_to_extract in structured_data['data']:
                    print(f"\n--- Extracted {field_to_extract} ---")
                    print(structured_data['data'][field_to_extract])
                elif field_to_extract == 'documentType' and 'documentType' in structured_data:
                    print(f"\n--- Extracted {field_to_extract} ---")
                    print(structured_data['documentType'])
                elif field_to_extract == 'rawText' and 'rawText' in structured_data:
                    print(f"\n--- Extracted {field_to_extract} ---")
                    print(structured_data['rawText'])
                else:
                    print(f"Field '{field_to_extract}' not found in the structured output or is not a top-level field.")
                    print("Available fields in 'data' object: " + ", ".join(structured_data.get('data', {}).keys()))
                    print("Available top-level fields: documentType, rawText")
        else:
            print("\nFailed to extract structured data.")

    # --- Optional: Local Tesseract OCR (without Gemini's understanding) ---
    # This part is just for demonstrating basic local OCR if you want to see raw text.
    # It does NOT provide structured output like the Gemini API call above.
    # try:
    #     print("\n--- Raw text from local Tesseract OCR (for comparison) ---")
    #     raw_text = pytesseract.image_to_string(Image.open(image_file_path))
    #     print(raw_text)
    # except pytesseract.TesseractNotFoundError:
    #     print("\nWarning: Tesseract OCR engine not found. Install it to use local OCR.")
    #     print("See: https://tesseract-ocr.github.io/tessdoc/Installation.html")
    # except Exception as e:
    #     print(f"\nError during local Tesseract OCR: {e}")

import base64
import json
import requests
import os
from PIL import Image
import pytesseract
import mimetypes # Import mimetypes module
import re # Import regex module for cleaning

# --- Configuration ---
# IMPORTANT: Replace with your actual Gemini API Key.
# You can get one from Google AI Studio: https://aistudio.google.com/app/apikey
GEMINI_API_KEY = "AIzaSyCmw6bXu01lQCM61V3LLGC8x1Rzgwn1bgw" # Your Gemini API key goes here

# Path to the Tesseract executable (e.g., 'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' on Windows)
# If tesseract is in your PATH, you might not need this line.
# pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract' # Example for macOS/Linux
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe' # Example for Windows

# --- Function to encode image to base64 ---
def image_to_base64(image_path):
    """Encodes an image file to a base64 string."""
    try:
        with open(image_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
        return encoded_string
    except FileNotFoundError:
        print(f"Error: Image file not found at {image_path}")
        return None
    except Exception as e:
        print(f"Error encoding image: {e}")
        return None

# --- Post-processing functions ---
def _clean_and_deduplicate_name(text_field):
    """
    Cleans and deduplicates name/father's name fields.
    Prioritizes English names if multiple languages are present.
    """
    if not isinstance(text_field, str):
        return text_field # Return as is if not a string

    lines = [line.strip() for line in text_field.split('\n') if line.strip()]

    cleaned_lines = []
    for line in lines:
        # Remove "S/O Sangappa Halakavatagi" or similar patterns if they repeat
        cleaned_line = re.sub(r'S/O\s+[\w\s]+', '', line, flags=re.IGNORECASE).strip()
        # Remove "1, 1," or similar artifacts
        cleaned_line = re.sub(r',\s*\d+,\s*\d+', '', cleaned_line).strip()
        if cleaned_line:
            cleaned_lines.append(cleaned_line)

    unique_lines = []
    seen = set()
    for line in cleaned_lines:
        if line not in seen:
            unique_lines.append(line)
            seen.add(line)

    english_names = [line for line in unique_lines if all(ord(char) < 128 for char in line)]

    if english_names:
        for name in english_names:
            if ' ' in name and len(name.split()) > 1:
                return name
        return english_names[0]

    if unique_lines:
        return unique_lines[0]

    return ""

def _clean_phone_number(text_field):
    """
    Extracts and cleans phone numbers from a string, removing extraneous text.
    Focuses on common mobile/landline formats and filters out Aadhar VIDs/numbers.
    """
    if not isinstance(text_field, str):
        return text_field

    # Regex to find common phone number patterns:
    # +? (optional plus sign)
    # \d{1,4} (1 to 4 digits for country code, optional)
    # [\s-]* (optional spaces or hyphens)
    # \d{6,10} (6 to 10 digits for the number itself - common mobile/landline lengths)
    # This pattern is designed to be more specific to phone numbers and less likely to pick up Aadhar numbers.
    phone_number_patterns = re.findall(r'(\+?\d{1,4}[\s-]?\d{6,10})', text_field)

    filtered_numbers = []
    for num in phone_number_patterns:
        # Remove spaces and hyphens for a clean digit count
        clean_num = re.sub(r'[\s-]', '', num)

        # Filter out Aadhar-like 12-digit numbers (often in blocks of 4)
        # And also filter out short numbers that are unlikely to be phone numbers
        if len(clean_num) >= 10 and len(clean_num) <= 15 and not re.fullmatch(r'(\d{4}\s?){2}\d{4}', clean_num):
            # Further filter common Aadhar VIDs if they appear as phone numbers
            if not (len(clean_num) == 12 and clean_num.startswith(('9193', '9194'))): # Example Aadhar VID prefixes
                filtered_numbers.append(num.strip())

    # Deduplicate and join unique valid phone numbers
    if filtered_numbers:
        return " / ".join(sorted(list(set(filtered_numbers))))
    return ""

def _clean_address(text_field):
    """
    Cleans and formats address strings by removing non-address related lines.
    """
    if not isinstance(text_field, str):
        return text_field

    lines = [line.strip() for line in text_field.split('\n') if line.strip()]

    filtered_lines = []
    for line in lines:
        # Skip lines that are just numbers (like Aadhar numbers or VIDs)
        if re.fullmatch(r'[\d\s]+', line):
            continue
        # Skip lines that contain "S/O" or similar name indicators
        if re.search(r'S/O\s+', line, re.IGNORECASE):
            continue
        # Skip lines that look like email or website
        if '@' in line or 'http' in line or 'www' in line:
            continue
        # Skip lines that contain common Aadhar phrases or official text
        if re.search(r'aadhaar|uidai|government of india|unique identification authority|download date|issue date|verify identity|electronically generated|citizenship|information', line, re.IGNORECASE):
            continue
        # Remove "1, 1," or similar artifacts often seen on Aadhar addresses
        cleaned_line = re.sub(r',\s*\d+,\s*\d+', '', line).strip()

        # Keep lines that contain common address keywords or look like address components
        # This is a heuristic, adjust as needed based on common address formats
        if cleaned_line and (
            re.search(r'\d', cleaned_line) or # Contains digits (house number, pin code)
            re.search(r'road|street|colony|nagar|gali|area|district|city|town|village|state|pin|post|taluk|tehsil', cleaned_line, re.IGNORECASE) or
            len(cleaned_line.split()) > 1 # More than one word
        ):
            filtered_lines.append(cleaned_line)

    # Deduplicate and join
    unique_lines = []
    seen = set()
    for line in filtered_lines:
        if line not in seen:
            unique_lines.append(line)
            seen.add(line)

    return ", ".join(unique_lines)


# --- Function to perform OCR using Gemini API ---
def perform_gemini_ocr(image_path):
    """
    Performs OCR and structured data extraction using the Gemini 2.0 Flash API.
    Args:
        image_path (str): The path to the input image file.
    Returns:
        dict: A dictionary containing the structured output from the LLM, or None if an error occurs.
    """
    if not GEMINI_API_KEY:
        print("Error: GEMINI_API_KEY is not set. Please provide your API key.")
        return None

    base64_image = image_to_base64(image_path)
    if not base64_image:
        return None

    # Determine MIME type using mimetypes module for better accuracy
    mime_type, _ = mimetypes.guess_type(image_path)
    if not mime_type or not mime_type.startswith('image/'):
        print(f"Warning: Could not determine valid image MIME type for {image_path}. Defaulting to image/jpeg.")
        mime_type = "image/jpeg" # Fallback

    print(f"Detected MIME type: {mime_type}")
    print(f"Base64 image data length: {len(base64_image)} characters") # Debug print

    # Define the prompt for the LLM - UPDATED FOR DEDUPLICATION AND SPECIFIC FIELDS
    prompt = """Analyze the following image.
    1. Identify the type of document: Is it a resume, an Aadhar card, a handwritten note, or something else?
    2. Extract all relevant information from the document.
    3. Provide the output in a structured JSON format.

    For a resume, extract: name, phoneNumber (only the contact number(s), no other numbers), email (only the email address(es)), education (degrees, institutions, years), experience (job titles, companies, dates, responsibilities).
    For an Aadhar card, extract:
        - name: Provide the full name. If multiple languages are present, try to provide both, but ensure each is a single instance.
        - father's name: Provide the full father's name. If multiple languages are present, try to provide both, but ensure each is a single instance.
        - date of birth
        - gender
        - Aadhar number (only the 12-digit number, no other numbers)
        - address (full mailing address, without extra details like "S/O", "VID", or other official text)
    For a handwritten document, extract the complete transcribed text.
    For any other document, extract the main text content.

    The JSON should have a 'documentType' field (e.g., "resume", "aadhar", "handwritten", "other") and a 'data' object containing the extracted fields. If it's handwritten, put the transcribed text in a 'extractedText' field within the 'data' object.
    """

    # Define the API endpoint
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"

    # Define the payload with image data and generation config - UPDATED SCHEMA
    payload = {
        "contents": [
            {
                "role": "user",
                "parts": [
                    {"text": prompt},
                    {
                        "inlineData": {
                            "mimeType": mime_type,
                            "data": base64_image
                        }
                    }
                ]
            }
        ],
        "generationConfig": {
            "responseMimeType": "application/json",
            "responseSchema": {
                "type": "OBJECT",
                "properties": {
                    "documentType": {
                        "type": "STRING",
                        "enum": ["resume", "aadhar", "handwritten", "other", "unknown"]
                    },
                    "data": {
                        "type": "OBJECT",
                        "properties": {
                            "name": {"type": "STRING"},
                            "fatherName": {"type": "STRING"}, # Added fatherName field
                            "dob": {"type": "STRING"},
                            "gender": {"type": "STRING"},
                            "address": {"type": "STRING"},
                            "idNumber": {"type": "STRING"}, # For Aadhar
                            "phoneNumber": {"type": "STRING"}, # Changed from 'contact' for resume
                            "email": {"type": "STRING"},     # Changed from 'contact' for resume
                            "education": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "experience": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "extractedText": {"type": "STRING"} # For handwritten or general text
                        },
                    },
                    "rawText": {"type": "STRING"} # Optional: to capture raw text if LLM provides it
                },
                "required": ["documentType", "data"]
            }
        }
    }

    headers = {
        "Content-Type": "application/json"
    }

    print("Sending request to Gemini API...")
    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(payload))
        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)
        result = response.json()

        if result.get("candidates") and len(result["candidates"]) > 0 and \
           result["candidates"][0].get("content") and result["candidates"][0]["content"].get("parts") and \
           len(result["candidates"][0]["content"]["parts"]) > 0:
            json_string = result["candidates"][0]["content"]["parts"][0]["text"]
            try:
                parsed_json = json.loads(json_string)
                # Apply post-processing here for all relevant fields
                if parsed_json.get("documentType") == "aadhar":
                    if "name" in parsed_json["data"]:
                        parsed_json["data"]["name"] = _clean_and_deduplicate_name(parsed_json["data"]["name"])
                    if "fatherName" in parsed_json["data"]:
                        parsed_json["data"]["fatherName"] = _clean_and_deduplicate_name(parsed_json["data"]["fatherName"])
                    if "phoneNumber" in parsed_json["data"]:
                        parsed_json["data"]["phoneNumber"] = _clean_phone_number(parsed_json["data"]["phoneNumber"])
                    if "address" in parsed_json["data"]:
                        parsed_json["data"]["address"] = _clean_address(parsed_json["data"]["address"])
                    # For Aadhar number, ensure it's just the 12 digits
                    if "idNumber" in parsed_json["data"]:
                        id_num = parsed_json["data"]["idNumber"]
                        # Extract only 12 digits, remove spaces/hyphens
                        clean_id_num = "".join(re.findall(r'\d', id_num))
                        if len(clean_id_num) == 12:
                            parsed_json["data"]["idNumber"] = clean_id_num
                        else:
                            # If not exactly 12 digits, try to find a 12-digit sequence
                            potential_ids = re.findall(r'\d{12}', id_num)
                            if potential_ids:
                                parsed_json["data"]["idNumber"] = potential_ids[0]
                            else:
                                parsed_json["data"]["idNumber"] = "" # Clear if not found
                # Add similar post-processing for resume if needed (e.g., for email/phone)
                elif parsed_json.get("documentType") == "resume":
                    if "phoneNumber" in parsed_json["data"]:
                        parsed_json["data"]["phoneNumber"] = _clean_phone_number(parsed_json["data"]["phoneNumber"])
                    # You might add email cleaning here too if needed

                return parsed_json
            except json.JSONDecodeError:
                print(f"Error: Failed to parse LLM response as JSON. Raw response: {json_string}")
                return None
        else:
            print(f"Error: No valid response from AI. Response: {result}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"An error occurred during API call: {e}")
        # Print the response content for more details on the 400 error
        if response is not None:
            print(f"API Response Content: {response.text}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None

# --- Main execution block ---
if __name__ == "__main__":
    # --- Example Usage ---
    # IMPORTANT: Replace 'path/to/your/image.jpg' with the actual path to your image file.
    # You can test with a resume, Aadhar card, or a handwritten note.
    image_file_path = "/content/sh adhar.jpg" # <--- This is the line to change

    if not os.path.exists(image_file_path):
        print(f"Error: The specified image file '{image_file_path}' does not exist.")
        print("Please update 'image_file_path' in the script to a valid image file on your system.")
    else:
        print(f"Processing image: {image_file_path}")

        # Prompt user for the desired field BEFORE performing OCR
        field_to_extract = input("\nEnter the single field you want to extract (e.g., name, address, phoneNumber, email, dob, fatherName, idNumber, extractedText, documentType): ").strip()

        structured_data = perform_gemini_ocr(image_file_path)

        if structured_data:
            print("\n--- Extracted Data for your request ---")
            if 'data' in structured_data and field_to_extract in structured_data['data']:
                print(f"{field_to_extract}: {structured_data['data'][field_to_extract]}")
            elif field_to_extract == 'documentType' and 'documentType' in structured_data:
                print(f"documentType: {structured_data['documentType']}")
            elif field_to_extract == 'rawText' and 'rawText' in structured_data:
                print(f"rawText: {structured_data['rawText']}")
            else:
                print(f"Field '{field_to_extract}' not found in the structured output.")
                print("Available fields in 'data' object: " + ", ".join(structured_data.get('data', {}).keys()))
                print("Available top-level fields: documentType, rawText")
        else:
            print("\nFailed to extract structured data.")

    # --- Optional: Local Tesseract OCR (without Gemini's understanding) ---
    # This part is just for demonstrating basic local OCR if you want to see raw text.
    # It does NOT provide structured output like the Gemini API call above.
    # try:
    #     print("\n--- Raw text from local Tesseract OCR (for comparison) ---")
    #     raw_text = pytesseract.image_to_string(Image.open(image_file_path))
    #     print(raw_text)
    # except pytesseract.TesseractNotFoundError:
    #     print("\nWarning: Tesseract OCR engine not found. Install it to use local OCR.")
    #     print("See: https://tesseract-ocr.github.io/tessdoc/Installation.html")
    # except Exception as e:
    #     print(f"\nError during local Tesseract OCR: {e}")

import base64
import json
import requests
import os
from PIL import Image
import pytesseract
import mimetypes # Import mimetypes module
import re # Import regex module for cleaning

# --- Configuration ---
# IMPORTANT: Replace with your actual Gemini API Key.
# You can get one from Google AI Studio: https://aistudio.google.com/app/apikey
GEMINI_API_KEY = "AIzaSyCmw6bXu01lQCM61V3LLGC8x1Rzgwn1bgw" # Your Gemini API key goes here

# Path to the Tesseract executable (e.g., 'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' on Windows)
# If tesseract is in your PATH, you might not need this line.
# pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract' # Example for macOS/Linux
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe' # Example for Windows

# --- Function to encode image to base64 ---
def image_to_base64(image_path):
    """Encodes an image file to a base64 string."""
    try:
        with open(image_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
        return encoded_string
    except FileNotFoundError:
        print(f"Error: Image file not found at {image_path}")
        return None
    except Exception as e:
        print(f"Error encoding image: {e}")
        return None

# --- Post-processing functions for cleaning extracted data ---
def _clean_and_deduplicate_name(text_field):
    """
    Cleans and deduplicates name/father's name fields.
    Prioritizes English names if multiple languages are present.
    """
    if not isinstance(text_field, str):
        return "" # Return empty string if not a string

    lines = [line.strip() for line in text_field.split('\n') if line.strip()]

    cleaned_lines = []
    for line in lines:
        # Remove "S/O Sangappa Halakavatagi" or similar patterns if they repeat
        cleaned_line = re.sub(r'S/O\s+[\w\s]+', '', line, flags=re.IGNORECASE).strip()
        # Remove "1, 1," or similar artifacts
        cleaned_line = re.sub(r',\s*\d+,\s*\d+', '', cleaned_line).strip()
        if cleaned_line:
            cleaned_lines.append(cleaned_line)

    unique_lines = []
    seen = set()
    for line in cleaned_lines:
        if line not in seen:
            unique_lines.append(line)
            seen.add(line)

    english_names = [line for line in unique_lines if all(ord(char) < 128 for char in line)]

    if english_names:
        for name in english_names:
            if ' ' in name and len(name.split()) > 1:
                return name
        return english_names[0]

    if unique_lines:
        return unique_lines[0]

    return ""

def _clean_phone_number(text_field):
    """
    Extracts and cleans phone numbers from a string, removing extraneous text.
    Focuses on common mobile/landline formats and filters out Aadhar VIDs/numbers.
    """
    if not isinstance(text_field, str):
        return ""

    # Regex to find common phone number patterns:
    # \b (word boundary)
    # (\+?\d{1,4})? (optional country code like +91)
    # [\s-]? (optional space or hyphen)
    # \d{6,10} (6 to 10 digits for the number itself)
    # \b (word boundary)
    phone_number_patterns = re.findall(r'\b(?:\+?\d{1,4}[\s-]?)?\d{6,10}\b', text_field)

    filtered_numbers = []
    for num in phone_number_patterns:
        clean_num = re.sub(r'[\s-]', '', num)

        # Filter out numbers that are too short or too long for typical phone numbers
        # Also, filter out numbers that look like Aadhar numbers (12 digits, often grouped by 4)
        if 8 <= len(clean_num) <= 15 and not re.fullmatch(r'(\d{4}\s?){2}\d{4}', clean_num):
            # Further filter common Aadhar VIDs if they appear as phone numbers
            if not (len(clean_num) == 12 and clean_num.startswith(('9193', '9194', '9195'))):
                filtered_numbers.append(num.strip())

    if filtered_numbers:
        return " / ".join(sorted(list(set(filtered_numbers))))
    return ""

def _clean_address(text_field):
    """
    Cleans and formats address strings by removing non-address related lines.
    Prioritizes lines that look like actual address components.
    """
    if not isinstance(text_field, str):
        return ""

    lines = [line.strip() for line in text_field.split('\n') if line.strip()]

    filtered_lines = []
    for line in lines:
        # Skip lines that are just numbers (like Aadhar numbers or VIDs)
        if re.fullmatch(r'[\d\s]+', line):
            continue
        # Skip lines that contain "S/O" or similar name indicators
        if re.search(r'S/O\s+', line, re.IGNORECASE):
            continue
        # Skip lines that look like email or website
        if '@' in line or 'http' in line or 'www' in line:
            continue
        # Skip lines that contain common Aadhar phrases or official text
        if re.search(r'aadhaar|uidai|government of india|unique identification authority|download date|issue date|verify identity|electronically generated|citizenship|information|my aadhaar|my identity|my proof|enrollment no\.', line, re.IGNORECASE):
            continue
        # Remove "1, 1," or similar artifacts often seen on Aadhar addresses
        cleaned_line = re.sub(r',\s*\d+,\s*\d+', '', cleaned_line).strip() # Apply after other filters

        # Keep lines that contain common address keywords or look like address components
        if cleaned_line and (
            re.search(r'\d', cleaned_line) or # Contains digits (house number, pin code)
            re.search(r'road|street|colony|nagar|gali|area|district|city|town|village|state|pin|post|taluk|tehsil|h\.no\.|flat|apartment|block|sector|phase|marg|vihar|enclave|c/o', cleaned_line, re.IGNORECASE) or
            len(cleaned_line.split()) > 1 # More than one word
        ):
            filtered_lines.append(cleaned_line)

    unique_lines = []
    seen = set()
    for line in filtered_lines:
        if line not in seen:
            unique_lines.append(line)
            seen.add(line)

    return ", ".join(unique_lines)

def _clean_id_number(text_field, raw_text_fallback=""):
    """
    Extracts and cleans a 12-digit Aadhar number. Prioritizes the direct field,
    then falls back to searching the raw text if necessary.
    """
    if not isinstance(text_field, str):
        text_field = "" # Ensure it's a string for regex

    # Try to find a 12-digit number directly in the field first
    clean_id_num = "".join(re.findall(r'\d', text_field))
    if len(clean_id_num) == 12:
        return clean_id_num

    # If not found or not clean, try to find it in the raw text fallback
    if raw_text_fallback and isinstance(raw_text_fallback, str):
        # Look for 12 digits, possibly with spaces or hyphens, typically grouped 4-4-4
        raw_id_match = re.search(r'\b(\d{4}[\s-]?\d{4}[\s-]?\d{4})\b', raw_text_fallback)
        if raw_id_match:
            return "".join(re.findall(r'\d', raw_id_match.group(1)))

    return "" # Return empty if not found

# --- New function to parse raw text output from LLM ---
def _parse_raw_text_to_structured_data(raw_llm_output):
    """
    Parses the raw text output from the LLM into a structured dictionary.
    """
    structured_data = {
        "documentType": "unknown",
        "data": {
            "name": "",
            "fatherName": "",
            "dob": "",
            "gender": "",
            "address": "",
            "idNumber": "",
            "phoneNumber": "",
            "email": "",
            "education": [],
            "experience": [],
            "extractedText": ""
        },
        "rawText": raw_llm_output # Keep the full raw text for debugging
    }

    # --- Document Type Detection ---
    if re.search(r'aadhar|uidai', raw_llm_output, re.IGNORECASE):
        structured_data["documentType"] = "aadhar"
    elif re.search(r'resume|experience|education|skills', raw_llm_output, re.IGNORECASE):
        structured_data["documentType"] = "resume"
    elif re.search(r'handwritten|note', raw_llm_output, re.IGNORECASE) and not structured_data["documentType"] in ["aadhar", "resume"]:
        structured_data["documentType"] = "handwritten"

    # --- General Text Extraction (for handwritten or 'other') ---
    if structured_data["documentType"] == "handwritten" or structured_data["documentType"] == "other":
        structured_data["data"]["extractedText"] = raw_llm_output.strip()
        return structured_data # If it's just text, no further parsing needed for other fields

    # --- Field Extraction (more specific for Aadhar/Resume) ---

    # Name (Aadhar/Resume)
    name_match = re.search(r'(?:Name|Shreeshail Halakavatagi)[:\s]*([^\n]+)', raw_llm_output, re.IGNORECASE)
    if name_match:
        structured_data["data"]["name"] = _clean_and_deduplicate_name(name_match.group(1))

    # Father's Name (Aadhar)
    father_name_match = re.search(r'(?:Father\'s Name|S/O)[:\s]*([^\n]+)', raw_llm_output, re.IGNORECASE)
    if father_name_match:
        structured_data["data"]["fatherName"] = _clean_and_deduplicate_name(father_name_match.group(1))

    # Date of Birth
    dob_match = re.search(r'(?:DOB|Date of Birth)[:\s]*(\d{2}[-/]\d{2}[-/]\d{4})', raw_llm_output, re.IGNORECASE)
    if dob_match:
        structured_data["data"]["dob"] = dob_match.group(1)

    # Gender
    gender_match = re.search(r'(?:Gender|Sex)[:\s]*(MALE|FEMALE|TRANSGENDER)', raw_llm_output, re.IGNORECASE)
    if gender_match:
        structured_data["data"]["gender"] = gender_match.group(1).upper()

    # Aadhar Number
    id_number_match = re.search(r'(?:Aadhar Number|ID Number|UID)[:\s]*([\d\s-]{12,19})', raw_llm_output, re.IGNORECASE)
    if id_number_match:
        structured_data["data"]["idNumber"] = _clean_id_number(id_number_match.group(1), raw_llm_output)
    else: # Fallback if LLM didn't put it in a specific field
        structured_data["data"]["idNumber"] = _clean_id_number("", raw_llm_output)

    # Phone Number
    phone_match = re.search(r'(?:Phone Number|Contact|Mobile)[:\s]*([^\n]+)', raw_llm_output, re.IGNORECASE)
    if phone_match:
        structured_data["data"]["phoneNumber"] = _clean_phone_number(phone_match.group(1))
    else: # Fallback
        structured_data["data"]["phoneNumber"] = _clean_phone_number(raw_llm_output)

    # Email
    email_match = re.search(r'(?:Email)[:\s]*([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})', raw_llm_output, re.IGNORECASE)
    if email_match:
        structured_data["data"]["email"] = email_match.group(1)

    # Address
    address_match = re.search(r'(?:Address)[:\s]*([^\n]+(?:\n[^\n]+)*)', raw_llm_output, re.IGNORECASE)
    if address_match:
        structured_data["data"]["address"] = _clean_address(address_match.group(1))
    else: # Fallback: try to find address patterns in the raw text
        structured_data["data"]["address"] = _clean_address(raw_llm_output)

    # Education (for resume) - Simplified extraction for now
    education_match = re.search(r'Education:([^\n]+(?:\n[^\n]+)*?)(?:Experience|Skills|$)', raw_llm_output, re.IGNORECASE | re.DOTALL)
    if education_match:
        structured_data["data"]["education"] = [line.strip() for line in education_match.group(1).split('\n') if line.strip()]

    # Experience (for resume) - Simplified extraction for now
    experience_match = re.search(r'Experience:([^\n]+(?:\n[^\n]+)*?)(?:Education|Skills|$)', raw_llm_output, re.IGNORECASE | re.DOTALL)
    if experience_match:
        structured_data["data"]["experience"] = [line.strip() for line in experience_match.group(1).split('\n') if line.strip()]

    return structured_data


# --- Function to perform OCR using Gemini API ---
def perform_gemini_ocr(image_path):
    """
    Performs OCR and structured data extraction using the Gemini 2.0 Flash API.
    Args:
        image_path (str): The path to the input image file.
    Returns:
        dict: A dictionary containing the structured output from the LLM, or None if an error occurs.
    """
    if not GEMINI_API_KEY:
        print("Error: GEMINI_API_KEY is not set. Please provide your API key.")
        return None

    base64_image = image_to_base64(image_path)
    if not base64_image:
        return None

    # Determine MIME type using mimetypes module for better accuracy
    mime_type, _ = mimetypes.guess_type(image_path)
    if not mime_type or not mime_type.startswith('image/'):
        print(f"Warning: Could not determine valid image MIME type for {image_path}. Defaulting to image/jpeg.")
        mime_type = "image/jpeg" # Fallback

    print(f"Detected MIME type: {mime_type}")
    print(f"Base64 image data length: {len(base64_image)} characters") # Debug print

    # Define the prompt for the LLM - Now asking for structured text, not JSON
    prompt = """Analyze the following image and extract the following information. Present each piece of information on a new line, clearly labeled.

    Document Type: [Identify if it's a Resume, Aadhar Card, Handwritten Document, or Other]
    Name: [Extracted Name]
    Father's Name: [Extracted Father's Name, if applicable]
    Date of Birth: [Extracted Date of Birth, e.g., DD/MM/YYYY]
    Gender: [Extracted Gender, e.g., MALE/FEMALE]
    Aadhar Number: [Extracted 12-digit Aadhar number, if applicable, without spaces or hyphens]
    Phone Number: [Extracted Phone Number(s), if applicable, clean and without other text]
    Email: [Extracted Email Address(es), if applicable]
    Address: [Extracted full mailing address, concise, without "S/O", "VID", Aadhar numbers, phone numbers, emails, website URLs, or other official/repetitive text. Only the physical address.]
    Education: [List of educational qualifications, if applicable, each on a new sub-line]
    Experience: [List of work experience, if applicable, each on a new sub-line]
    Extracted Text: [Full raw text content of the document, if it's a handwritten document or general text]

    Ensure that the Aadhar Number, Phone Number, and Address fields contain ONLY the requested information and are free from extraneous text, VIDs, or other document artifacts. If a field is not found, leave it blank or state 'N/A'.
    """

    # Define the API endpoint
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"

    # Define the payload with image data - NO responseSchema now, expect raw text
    payload = {
        "contents": [
            {
                "role": "user",
                "parts": [
                    {"text": prompt},
                    {
                        "inlineData": {
                            "mimeType": mime_type,
                            "data": base64_image
                        }
                    }
                ]
            }
        ]
    }

    headers = {
        "Content-Type": "application/json"
    }

    print("Sending request to Gemini API...")
    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(payload))
        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)
        result = response.json()

        if result.get("candidates") and len(result["candidates"]) > 0 and \
           result["candidates"][0].get("content") and result["candidates"][0]["content"].get("parts") and \
           len(result["candidates"][0]["content"]["parts"]) > 0:
            raw_llm_output = result["candidates"][0]["content"]["parts"][0]["text"]
            print("\n--- Raw LLM Output (for debugging) ---")
            print(raw_llm_output) # Print raw output to see what LLM returned

            # Parse the raw text into structured data
            structured_data = _parse_raw_text_to_structured_data(raw_llm_output)

            return structured_data
        else:
            print(f"Error: No valid response from AI. Response: {result}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"An error occurred during API call: {e}")
        if response is not None:
            print(f"API Response Content: {response.text}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None

# --- Main execution block ---
if __name__ == "__main__":
    # --- Example Usage ---
    # IMPORTANT: Replace 'path/to/your/image.jpg' with the actual path to your image file.
    # You can test with a resume, Aadhar card, or a handwritten note.
    image_file_path = "/content/sh adhar.jpg" # <--- This is the line to change

    if not os.path.exists(image_file_path):
        print(f"Error: The specified image file '{image_file_path}' does not exist.")
        print("Please update 'image_file_path' in the script to a valid image file on your system.")
    else:
        print(f"Processing image: {image_file_path}")

        # Prompt user for the desired field BEFORE performing OCR
        field_to_extract = input("\nEnter the single field you want to extract (e.g., name, address, phoneNumber, email, dob, fatherName, idNumber, extractedText, documentType): ").strip()

        structured_data = perform_gemini_ocr(image_file_path)

        if structured_data:
            print("\n--- Extracted Data for your request ---")
            # Check for fields in 'data' object first
            if 'data' in structured_data and field_to_extract in structured_data['data']:
                print(f"{field_to_extract}: {structured_data['data'][field_to_extract]}")
            # Check for top-level fields
            elif field_to_extract == 'documentType' and 'documentType' in structured_data:
                print(f"documentType: {structured_data['documentType']}")
            elif field_to_extract == 'rawText' and 'rawText' in structured_data:
                print(f"rawText: {structured_data['rawText']}")
            else:
                print(f"Field '{field_to_extract}' not found in the structured output.")
                print("Available fields in 'data' object: " + ", ".join(structured_data.get('data', {}).keys()))
                print("Available top-level fields: documentType, rawText")
        else:
            print("\nFailed to extract structured data.")

    # --- Optional: Local Tesseract OCR (without Gemini's understanding) ---
    # This part is just for demonstrating basic local OCR if you want to see raw text.
    # It does NOT provide structured output like the Gemini API call above.
    # try:
    #     print("\n--- Raw text from local Tesseract OCR (for comparison) ---")
    #     raw_text = pytesseract.image_to_string(Image.open(image_file_path))
    #     print(raw_text)
    # except pytesseract.TesseractNotFoundError:
    #     print("\nWarning: Tesseract OCR engine not found. Install it to use local OCR.")
    #     print("See: https://tesseract-ocr.github.io/tessdoc/Installation.html")
    # except Exception as e:
    #     print(f"\nError during local Tesseract OCR: {e}")

import base64
import json
import requests
import os
from PIL import Image
import pytesseract
import mimetypes # Import mimetypes module
import re # Import regex module for cleaning

# --- Configuration ---
# IMPORTANT: Replace with your actual Gemini API Key.
# You can get one from Google AI Studio: https://aistudio.google.com/app/apikey
GEMINI_API_KEY = "AIzaSyCmw6bXu01lQCM61V3LLGC8x1Rzgwn1bgw" # Your Gemini API key goes here

# Path to the Tesseract executable (e.g., 'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' on Windows)
# If tesseract is in your PATH, you might not need this line.
# pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract' # Example for macOS/Linux
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe' # Example for Windows

# --- Function to encode image to base64 ---
def image_to_base64(image_path):
    """Encodes an image file to a base64 string."""
    try:
        with open(image_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
        return encoded_string
    except FileNotFoundError:
        print(f"Error: Image file not found at {image_path}")
        return None
    except Exception as e:
        print(f"Error encoding image: {e}")
        return None

# --- Post-processing functions for cleaning extracted data ---
def _clean_and_deduplicate_name(text_field):
    """
    Cleans and deduplicates name/father's name fields.
    Prioritizes English names if multiple languages are present.
    """
    if not isinstance(text_field, str):
        return "" # Return empty string if not a string

    lines = [line.strip() for line in text_field.split('\n') if line.strip()]

    cleaned_lines = []
    for line in lines:
        # Remove "S/O Sangappa Halakavatagi" or similar patterns if they repeat
        cleaned_line = re.sub(r'S/O\s+[\w\s]+', '', line, flags=re.IGNORECASE).strip()
        # Remove "1, 1," or similar artifacts
        cleaned_line = re.sub(r',\s*\d+,\s*\d+', '', cleaned_line).strip()
        if cleaned_line:
            cleaned_lines.append(cleaned_line)

    unique_lines = []
    seen = set()
    for line in cleaned_lines:
        if line not in seen:
            unique_lines.append(line)
            seen.add(line)

    english_names = [line for line in unique_lines if all(ord(char) < 128 for char in line)]

    if english_names:
        for name in english_names:
            if ' ' in name and len(name.split()) > 1:
                return name
        return english_names[0]

    if unique_lines:
        return unique_lines[0]

    return ""

def _clean_phone_number(text_field):
    """
    Extracts and cleans phone numbers from a string, removing extraneous text.
    Focuses on common mobile/landline formats and filters out Aadhar VIDs/numbers.
    """
    if not isinstance(text_field, str):
        return ""

    # Regex to find common phone number patterns:
    # \b (word boundary)
    # (\+?\d{1,4})? (optional country code like +91)
    # [\s-]? (optional space or hyphen)
    # \d{6,10} (6 to 10 digits for the number itself)
    # \b (word boundary)
    phone_number_patterns = re.findall(r'\b(?:\+?\d{1,4}[\s-]?)?\d{6,10}\b', text_field)

    filtered_numbers = []
    for num in phone_number_patterns:
        clean_num = re.sub(r'[\s-]', '', num)

        # Filter out numbers that are too short or too long for typical phone numbers
        # Also, filter out numbers that look like Aadhar numbers (12 digits, often grouped by 4)
        if 8 <= len(clean_num) <= 15 and not re.fullmatch(r'(\d{4}\s?){2}\d{4}', clean_num):
            # Further filter common Aadhar VIDs if they appear as phone numbers
            if not (len(clean_num) == 12 and clean_num.startswith(('9193', '9194', '9195'))):
                filtered_numbers.append(num.strip())

    if filtered_numbers:
        return " / ".join(sorted(list(set(filtered_numbers))))
    return ""

def _clean_address(text_field):
    """
    Cleans and formats address strings by removing non-address related lines.
    Prioritizes lines that look like actual address components.
    """
    if not isinstance(text_field, str):
        return ""

    lines = [line.strip() for line in text_field.split('\n') if line.strip()]

    filtered_lines = []
    for line in lines:
        cleaned_line = line # Initialize with the current line from the loop

        # Skip lines that are just numbers (like Aadhar numbers or VIDs)
        if re.fullmatch(r'[\d\s]+', cleaned_line):
            continue
        # Skip lines that contain "S/O" or similar name indicators
        if re.search(r'S/O\s+', cleaned_line, re.IGNORECASE):
            continue
        # Skip lines that look like email or website
        if '@' in cleaned_line or 'http' in cleaned_line or 'www' in cleaned_line:
            continue
        # Skip lines that contain common Aadhar phrases or official text
        if re.search(r'aadhaar|uidai|government of india|unique identification authority|download date|issue date|verify identity|electronically generated|citizenship|information|my aadhaar|my identity|my proof|enrollment no\.', cleaned_line, re.IGNORECASE):
            continue

        # Remove "1, 1," or similar artifacts often seen on Aadhar addresses
        cleaned_line = re.sub(r',\s*\d+,\s*\d+', '', cleaned_line).strip()

        # Keep lines that contain common address keywords or look like address components
        if cleaned_line and (
            re.search(r'\d', cleaned_line) or # Contains digits (house number, pin code)
            re.search(r'road|street|colony|nagar|gali|area|district|city|town|village|state|pin|post|taluk|tehsil|h\.no\.|flat|apartment|block|sector|phase|marg|vihar|enclave|c/o', cleaned_line, re.IGNORECASE) or
            len(cleaned_line.split()) > 1 # More than one word
        ):
            filtered_lines.append(cleaned_line)

    unique_lines = []
    seen = set()
    for line in filtered_lines:
        if line not in seen:
            unique_lines.append(line)
            seen.add(line)

    return ", ".join(unique_lines)

def _clean_id_number(text_field, raw_text_fallback=""):
    """
    Extracts and cleans a 12-digit Aadhar number. Prioritizes the direct field,
    then falls back to searching the raw text if necessary.
    """
    if not isinstance(text_field, str):
        text_field = "" # Ensure it's a string for regex

    # Try to find a 12-digit number directly in the field first
    clean_id_num = "".join(re.findall(r'\d', text_field))
    if len(clean_id_num) == 12:
        return clean_id_num

    # If not found or not clean, try to find it in the raw text fallback
    if raw_text_fallback and isinstance(raw_text_fallback, str):
        # Look for 12 digits, possibly with spaces or hyphens, typically grouped 4-4-4
        raw_id_match = re.search(r'\b(\d{4}[\s-]?\d{4}[\s-]?\d{4})\b', raw_text_fallback)
        if raw_id_match:
            return "".join(re.findall(r'\d', raw_id_match.group(1)))

    return "" # Return empty if not found

# --- New function to parse raw text output from LLM ---
def _parse_raw_text_to_structured_data(raw_llm_output):
    """
    Parses the raw text output from the LLM into a structured dictionary.
    """
    structured_data = {
        "documentType": "unknown",
        "data": {
            "name": "",
            "fatherName": "",
            "dob": "",
            "gender": "",
            "address": "",
            "idNumber": "",
            "phoneNumber": "",
            "email": "",
            "education": [],
            "experience": [],
            "extractedText": ""
        },
        "rawText": raw_llm_output # Keep the full raw text for debugging
    }

    # --- Document Type Detection ---
    if re.search(r'aadhar|uidai', raw_llm_output, re.IGNORECASE):
        structured_data["documentType"] = "aadhar"
    elif re.search(r'resume|experience|education|skills', raw_llm_output, re.IGNORECASE):
        structured_data["documentType"] = "resume"
    elif re.search(r'handwritten|note', raw_llm_output, re.IGNORECASE) and not structured_data["documentType"] in ["aadhar", "resume"]:
        structured_data["documentType"] = "handwritten"

    # --- General Text Extraction (for handwritten or 'other') ---
    if structured_data["documentType"] == "handwritten" or structured_data["documentType"] == "other":
        structured_data["data"]["extractedText"] = raw_llm_output.strip()
        return structured_data # If it's just text, no further parsing needed for other fields

    # --- Field Extraction (more specific for Aadhar/Resume) ---

    # Name (Aadhar/Resume)
    name_match = re.search(r'(?:Name)[:\s]*([^\n]+)', raw_llm_output, re.IGNORECASE)
    if name_match:
        structured_data["data"]["name"] = _clean_and_deduplicate_name(name_match.group(1))
    else: # Fallback for Aadhar-like names if "Name:" label is missing
        aadhar_name_fallback = re.search(r'Shreeshail Halakavatagi', raw_llm_output, re.IGNORECASE)
        if aadhar_name_fallback:
            structured_data["data"]["name"] = _clean_and_deduplicate_name(aadhar_name_fallback.group(0))

    # Father's Name (Aadhar)
    father_name_match = re.search(r'(?:Father\'s Name|S/O)[:\s]*([^\n]+)', raw_llm_output, re.IGNORECASE)
    if father_name_match:
        structured_data["data"]["fatherName"] = _clean_and_deduplicate_name(father_name_match.group(1))

    # Date of Birth
    dob_match = re.search(r'(?:DOB|Date of Birth)[:\s]*(\d{2}[-/]\d{2}[-/]\d{4})', raw_llm_output, re.IGNORECASE)
    if dob_match:
        structured_data["data"]["dob"] = dob_match.group(1)

    # Gender
    gender_match = re.search(r'(?:Gender|Sex)[:\s]*(MALE|FEMALE|TRANSGENDER)', raw_llm_output, re.IGNORECASE)
    if gender_match:
        structured_data["data"]["gender"] = gender_match.group(1).upper()

    # Aadhar Number
    id_number_match = re.search(r'(?:Aadhar Number|ID Number|UID)[:\s]*([\d\s-]{12,19})', raw_llm_output, re.IGNORECASE)
    if id_number_match:
        structured_data["data"]["idNumber"] = _clean_id_number(id_number_match.group(1), raw_llm_output)
    else: # Fallback if LLM didn't put it in a specific field
        structured_data["data"]["idNumber"] = _clean_id_number("", raw_llm_output)

    # Phone Number
    phone_match = re.search(r'(?:Phone Number|Contact|Mobile)[:\s]*([^\n]+)', raw_llm_output, re.IGNORECASE)
    if phone_match:
        structured_data["data"]["phoneNumber"] = _clean_phone_number(phone_match.group(1))
    else: # Fallback
        structured_data["data"]["phoneNumber"] = _clean_phone_number(raw_llm_output)

    # Email
    email_match = re.search(r'(?:Email)[:\s]*([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})', raw_llm_output, re.IGNORECASE)
    if email_match:
        structured_data["data"]["email"] = email_match.group(1)

    # Address
    address_match = re.search(r'(?:Address)[:\s]*([^\n]+(?:\n[^\n]+)*)', raw_llm_output, re.IGNORECASE)
    if address_match:
        structured_data["data"]["address"] = _clean_address(address_match.group(1))
    else: # Fallback: try to find address patterns in the raw text
        structured_data["data"]["address"] = _clean_address(raw_llm_output)

    # Education (for resume) - Simplified extraction for now
    education_match = re.search(r'Education:([^\n]+(?:\n[^\n]+)*?)(?:Experience|Skills|$)', raw_llm_output, re.IGNORECASE | re.DOTALL)
    if education_match:
        structured_data["data"]["education"] = [line.strip() for line in education_match.group(1).split('\n') if line.strip()]

    # Experience (for resume) - Simplified extraction for now
    experience_match = re.search(r'Experience:([^\n]+(?:\n[^\n]+)*?)(?:Education|Skills|$)', raw_llm_output, re.IGNORECASE | re.DOTALL)
    if experience_match:
        structured_data["data"]["experience"] = [line.strip() for line in experience_match.group(1).split('\n') if line.strip()]

    return structured_data


# --- Function to perform OCR using Gemini API ---
def perform_gemini_ocr(image_path):
    """
    Performs OCR and structured data extraction using the Gemini 2.0 Flash API.
    Args:
        image_path (str): The path to the input image file.
    Returns:
        dict: A dictionary containing the structured output from the LLM, or None if an error occurs.
    """
    if not GEMINI_API_KEY:
        print("Error: GEMINI_API_KEY is not set. Please provide your API key.")
        return None

    base64_image = image_to_base64(image_path)
    if not base64_image:
        return None

    # Determine MIME type using mimetypes module for better accuracy
    mime_type, _ = mimetypes.guess_type(image_path)
    if not mime_type or not mime_type.startswith('image/'):
        print(f"Warning: Could not determine valid image MIME type for {image_path}. Defaulting to image/jpeg.")
        mime_type = "image/jpeg" # Fallback

    print(f"Detected MIME type: {mime_type}")
    print(f"Base64 image data length: {len(base64_image)} characters") # Debug print

    # Define the prompt for the LLM - Now asking for structured text, not JSON
    prompt = """Analyze the following image and extract the following information. Present each piece of information on a new line, clearly labeled.

    Document Type: [Identify if it's a Resume, Aadhar Card, Handwritten Document, or Other]
    Name: [Extracted Name]
    Father's Name: [Extracted Father's Name, if applicable]
    Date of Birth: [Extracted Date of Birth, e.g., DD/MM/YYYY]
    Gender: [Extracted Gender, e.g., MALE/FEMALE]
    Aadhar Number: [Extracted 12-digit Aadhar number, if applicable, without spaces or hyphens]
    Phone Number: [Extracted Phone Number(s), if applicable, clean and without other text]
    Email: [Extracted Email Address(es), if applicable]
    Address: [Extracted full mailing address, concise, without "S/O", "VID", Aadhar numbers, phone numbers, emails, website URLs, or other official/repetitive text. Only the physical address.]
    Education: [List of educational qualifications, if applicable, each on a new sub-line]
    Experience: [List of work experience, if applicable, each on a new sub-line]
    Extracted Text: [Full raw text content of the document, if it's a handwritten document or general text]

    Ensure that the Aadhar Number, Phone Number, and Address fields contain ONLY the requested information and are free from extraneous text, VIDs, or other document artifacts. If a field is not found, leave it blank or state 'N/A'.
    """

    # Define the API endpoint
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"

    # Define the payload with image data - NO responseSchema now, expect raw text
    payload = {
        "contents": [
            {
                "role": "user",
                "parts": [
                    {"text": prompt},
                    {
                        "inlineData": {
                            "mimeType": mime_type,
                            "data": base64_image
                        }
                    }
                ]
            }
        ]
    }

    headers = {
        "Content-Type": "application/json"
    }

    print("Sending request to Gemini API...")
    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(payload))
        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)
        result = response.json()

        if result.get("candidates") and len(result["candidates"]) > 0 and \
           result["candidates"][0].get("content") and result["candidates"][0]["content"].get("parts") and \
           len(result["candidates"][0]["content"]["parts"]) > 0:
            raw_llm_output = result["candidates"][0]["content"]["parts"][0]["text"]
            print("\n--- Raw LLM Output (for debugging) ---")
            print(raw_llm_output) # Print raw output to see what LLM returned

            # Parse the raw text into structured data
            structured_data = _parse_raw_text_to_structured_data(raw_llm_output)

            return structured_data
        else:
            print(f"Error: No valid response from AI. Response: {result}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"An error occurred during API call: {e}")
        if response is not None:
            print(f"API Response Content: {response.text}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None

# --- Main execution block ---
if __name__ == "__main__":
    # --- Example Usage ---
    # IMPORTANT: Replace 'path/to/your/image.jpg' with the actual path to your image file.
    # You can test with a resume, Aadhar card, or a handwritten note.
    image_file_path = "/content/sh adhar.jpg" # <--- This is the line to change

    if not os.path.exists(image_file_path):
        print(f"Error: The specified image file '{image_file_path}' does not exist.")
        print("Please update 'image_file_path' in the script to a valid image file on your system.")
    else:
        print(f"Processing image: {image_file_path}")

        # Prompt user for the desired field BEFORE performing OCR
        field_to_extract = input("\nEnter the single field you want to extract (e.g., name, address, phoneNumber, email, dob, fatherName, idNumber, extractedText, documentType): ").strip()

        structured_data = perform_gemini_ocr(image_file_path)

        if structured_data:
            print("\n--- Extracted Data for your request ---")
            # Check for fields in 'data' object first
            if 'data' in structured_data and field_to_extract in structured_data['data']:
                print(f"{field_to_extract}: {structured_data['data'][field_to_extract]}")
            # Check for top-level fields
            elif field_to_extract == 'documentType' and 'documentType' in structured_data:
                print(f"documentType: {structured_data['documentType']}")
            elif field_to_extract == 'rawText' and 'rawText' in structured_data:
                print(f"rawText: {structured_data['rawText']}")
            else:
                print(f"Field '{field_to_extract}' not found in the structured output.")
                print("Available fields in 'data' object: " + ", ".join(structured_data.get('data', {}).keys()))
                print("Available top-level fields: documentType, rawText")
        else:
            print("\nFailed to extract structured data.")

    # --- Optional: Local Tesseract OCR (without Gemini's understanding) ---
    # This part is just for demonstrating basic local OCR if you want to see raw text.
    # It does NOT provide structured output like the Gemini API call above.
    # try:
    #     print("\n--- Raw text from local Tesseract OCR (for comparison) ---")
    #     raw_text = pytesseract.image_to_string(Image.open(image_file_path))
    #     print(raw_text)
    # except pytesseract.TesseractNotFoundError:
    #     print("\nWarning: Tesseract OCR engine not found. Install it to use local OCR.")
    #     print("See: https://tesseract-ocr.github.io/tessdoc/Installation.html")
    # except Exception as e:
    #     print(f"\nError during local Tesseract OCR: {e}")

import base64
import json
import requests
import os
from PIL import Image
import pytesseract
import mimetypes # Import mimetypes module
import re # Import regex module for cleaning

# --- Configuration ---
# IMPORTANT: Replace with your actual Gemini API Key.
# You can get one from Google AI Studio: https://aistudio.google.com/app/apikey
GEMINI_API_KEY = "AIzaSyCmw6bXu01lQCM61V3LLGC8x1Rzgwn1bgw" # Your Gemini API key goes here

# Path to the Tesseract executable (e.g., 'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' on Windows)
# If tesseract is in your PATH, you might not need this line.
# pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract' # Example for macOS/Linux
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe' # Example for Windows

# --- Function to encode image to base64 ---
def image_to_base64(image_path):
    """Encodes an image file to a base64 string."""
    try:
        with open(image_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
        return encoded_string
    except FileNotFoundError:
        print(f"Error: Image file not found at {image_path}")
        return None
    except Exception as e:
        print(f"Error encoding image: {e}")
        return None

# --- Post-processing functions for cleaning extracted data ---
def _clean_and_deduplicate_name(text_field):
    """
    Cleans and deduplicates name/father's name fields.
    Prioritizes English names if multiple languages are present.
    """
    if not isinstance(text_field, str):
        return "" # Return empty string if not a string

    lines = [line.strip() for line in text_field.split('\n') if line.strip()]

    cleaned_lines = []
    for line in lines:
        # Remove "S/O Sangappa Halakavatagi" or similar patterns if they repeat
        cleaned_line = re.sub(r'S/O\s+[\w\s]+', '', line, flags=re.IGNORECASE).strip()
        # Remove "1, 1," or similar artifacts
        cleaned_line = re.sub(r',\s*\d+,\s*\d+', '', cleaned_line).strip()
        if cleaned_line:
            cleaned_lines.append(cleaned_line)

    unique_lines = []
    seen = set()
    for line in cleaned_lines:
        if line not in seen:
            unique_lines.append(line)
            seen.add(line)

    english_names = [line for line in unique_lines if all(ord(char) < 128 for char in line)]

    if english_names:
        for name in english_names:
            if ' ' in name and len(name.split()) > 1:
                return name
        return english_names[0]

    if unique_lines:
        return unique_lines[0]

    return ""

def _clean_phone_number(text_field):
    """
    Extracts and cleans phone numbers from a string, removing extraneous text.
    Focuses on common mobile/landline formats and filters out Aadhar VIDs/numbers.
    """
    if not isinstance(text_field, str):
        return ""

    # Regex to find common phone number patterns:
    # \b (word boundary)
    # (\+?\d{1,4})? (optional country code like +91)
    # [\s-]? (optional space or hyphen)
    # \d{6,10} (6 to 10 digits for the number itself)
    # \b (word boundary)
    phone_number_patterns = re.findall(r'\b(?:\+?\d{1,4}[\s-]?)?\d{6,10}\b', text_field)

    filtered_numbers = []
    for num in phone_number_patterns:
        clean_num = re.sub(r'[\s-]', '', num)

        # Filter out numbers that are too short or too long for typical phone numbers
        # Also, filter out numbers that look like Aadhar numbers (12 digits, often grouped by 4)
        if 8 <= len(clean_num) <= 15 and not re.fullmatch(r'(\d{4}\s?){2}\d{4}', clean_num):
            # Further filter common Aadhar VIDs if they appear as phone numbers
            if not (len(clean_num) == 12 and clean_num.startswith(('9193', '9194', '9195'))):
                filtered_numbers.append(num.strip())

    if filtered_numbers:
        return " / ".join(sorted(list(set(filtered_numbers))))
    return ""

def _clean_address(text_field):
    """
    Cleans and formats address strings by removing non-address related lines.
    Prioritizes lines that look like actual address components.
    """
    if not isinstance(text_field, str):
        return ""

    lines = [line.strip() for line in text_field.split('\n') if line.strip()]

    filtered_lines = []
    for line in lines:
        cleaned_line = line # Initialize with the current line from the loop

        # Skip lines that are just numbers (like Aadhar numbers or VIDs)
        if re.fullmatch(r'[\d\s]+', cleaned_line):
            continue
        # Skip lines that contain "S/O" or similar name indicators
        if re.search(r'S/O\s+', cleaned_line, re.IGNORECASE):
            continue
        # Skip lines that look like email or website
        if '@' in cleaned_line or 'http' in cleaned_line or 'www' in cleaned_line:
            continue
        # Skip lines that contain common Aadhar phrases or official text
        if re.search(r'aadhaar|uidai|government of india|unique identification authority|download date|issue date|verify identity|electronically generated|citizenship|information|my aadhaar|my identity|my proof|enrollment no\.', cleaned_line, re.IGNORECASE):
            continue

        # Remove "1, 1," or similar artifacts often seen on Aadhar addresses
        cleaned_line = re.sub(r',\s*\d+,\s*\d+', '', cleaned_line).strip()

        # Keep lines that contain common address keywords or look like address components
        if cleaned_line and (
            re.search(r'\d', cleaned_line) or # Contains digits (house number, pin code)
            re.search(r'road|street|colony|nagar|gali|area|district|city|town|village|state|pin|post|taluk|tehsil|h\.no\.|flat|apartment|block|sector|phase|marg|vihar|enclave|c/o', cleaned_line, re.IGNORECASE) or
            len(cleaned_line.split()) > 1 # More than one word
        ):
            filtered_lines.append(cleaned_line)

    unique_lines = []
    seen = set()
    for line in filtered_lines:
        if line not in seen:
            unique_lines.append(line)
            seen.add(line)

    return ", ".join(unique_lines)

def _clean_id_number(text_field, raw_text_fallback=""):
    """
    Extracts and cleans a 12-digit Aadhar number. Prioritizes the direct field,
    then falls back to searching the raw text if necessary.
    """
    if not isinstance(text_field, str):
        text_field = "" # Ensure it's a string for regex

    # Try to find a 12-digit number directly in the field first
    clean_id_num = "".join(re.findall(r'\d', text_field))
    if len(clean_id_num) == 12:
        return clean_id_num

    # If not found or not clean, try to find it in the raw text fallback
    if raw_text_fallback and isinstance(raw_text_fallback, str):
        # Look for 12 digits, possibly with spaces or hyphens, typically grouped 4-4-4
        raw_id_match = re.search(r'\b(\d{4}[\s-]?\d{4}[\s-]?\d{4})\b', raw_text_fallback)
        if raw_id_match:
            return "".join(re.findall(r'\d', raw_id_match.group(1)))

    return "" # Return empty if not found

# --- New function to parse raw text output from LLM ---
def _parse_raw_text_to_structured_data(raw_llm_output):
    """
    Parses the raw text output from the LLM into a structured dictionary.
    """
    structured_data = {
        "documentType": "unknown",
        "data": {
            "name": "",
            "fatherName": "",
            "dob": "",
            "gender": "",
            "address": "",
            "idNumber": "",
            "phoneNumber": "",
            "email": "",
            "education": [],
            "experience": [],
            "skills": [], # Added new skills field
            "extractedText": ""
        },
        "rawText": raw_llm_output # Keep the full raw text for debugging
    }

    # --- Document Type Detection ---
    if re.search(r'aadhar|uidai', raw_llm_output, re.IGNORECASE):
        structured_data["documentType"] = "aadhar"
    elif re.search(r'resume|experience|education|skills', raw_llm_output, re.IGNORECASE):
        structured_data["documentType"] = "resume"
    elif re.search(r'handwritten|note', raw_llm_output, re.IGNORECASE) and not structured_data["documentType"] in ["aadhar", "resume"]:
        structured_data["documentType"] = "handwritten"

    # --- General Text Extraction (for handwritten or 'other') ---
    if structured_data["documentType"] == "handwritten" or structured_data["documentType"] == "other":
        structured_data["data"]["extractedText"] = raw_llm_output.strip()
        return structured_data # If it's just text, no further parsing needed for other fields

    # --- Field Extraction (more specific for Aadhar/Resume) ---

    # Name (Aadhar/Resume)
    name_match = re.search(r'(?:Name)[:\s]*([^\n]+)', raw_llm_output, re.IGNORECASE)
    if name_match:
        structured_data["data"]["name"] = _clean_and_deduplicate_name(name_match.group(1))
    else: # Fallback for Aadhar-like names if "Name:" label is missing
        # This fallback might need to be more generic if the Aadhar name doesn't always appear like "Shreeshail Halakavatagi"
        aadhar_name_fallback = re.search(r'Shreeshail S H', raw_llm_output, re.IGNORECASE) # Adjusted for resume example
        if aadhar_name_fallback:
            structured_data["data"]["name"] = _clean_and_deduplicate_name(aadhar_name_fallback.group(0))

    # Father's Name (Aadhar)
    father_name_match = re.search(r'(?:Father\'s Name|S/O)[:\s]*([^\n]+)', raw_llm_output, re.IGNORECASE)
    if father_name_match:
        structured_data["data"]["fatherName"] = _clean_and_deduplicate_name(father_name_match.group(1))

    # Date of Birth
    dob_match = re.search(r'(?:DOB|Date of Birth)[:\s]*(\d{2}[-/]\d{2}[-/]\d{4})', raw_llm_output, re.IGNORECASE)
    if dob_match:
        structured_data["data"]["dob"] = dob_match.group(1)

    # Gender
    gender_match = re.search(r'(?:Gender|Sex)[:\s]*(MALE|FEMALE|TRANSGENDER)', raw_llm_output, re.IGNORECASE)
    if gender_match:
        structured_data["data"]["gender"] = gender_match.group(1).upper()

    # Aadhar Number
    id_number_match = re.search(r'(?:Aadhar Number|ID Number|UID)[:\s]*([\d\s-]{12,19})', raw_llm_output, re.IGNORECASE)
    if id_number_match:
        structured_data["data"]["idNumber"] = _clean_id_number(id_number_match.group(1), raw_llm_output)
    else: # Fallback if LLM didn't put it in a specific field
        structured_data["data"]["idNumber"] = _clean_id_number("", raw_llm_output)

    # Phone Number
    phone_match = re.search(r'(?:Phone Number|Contact|Mobile)[:\s]*([^\n]+)', raw_llm_output, re.IGNORECASE)
    if phone_match:
        structured_data["data"]["phoneNumber"] = _clean_phone_number(phone_match.group(1))
    else: # Fallback
        structured_data["data"]["phoneNumber"] = _clean_phone_number(raw_llm_output)

    # Email
    email_match = re.search(r'(?:Email)[:\s]*([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})', raw_llm_output, re.IGNORECASE)
    if email_match:
        structured_data["data"]["email"] = email_match.group(1)

    # Address
    address_match = re.search(r'(?:Address)[:\s]*([^\n]+(?:\n[^\n]+)*)', raw_llm_output, re.IGNORECASE)
    if address_match:
        structured_data["data"]["address"] = _clean_address(address_match.group(1))
    else: # Fallback: try to find address patterns in the raw text
        structured_data["data"]["address"] = _clean_address(raw_llm_output)

    # Education (for resume) - Simplified extraction for now
    education_match = re.search(r'Education:([^\n]+(?:\n[^\n]+)*?)(?:Experience|Skills|$)', raw_llm_output, re.IGNORECASE | re.DOTALL)
    if education_match:
        structured_data["data"]["education"] = [line.strip() for line in education_match.group(1).split('\n') if line.strip()]

    # Experience (for resume) - Simplified extraction for now
    experience_match = re.search(r'Experience:([^\n]+(?:\n[^\n]+)*?)(?:Education|Skills|$)', raw_llm_output, re.IGNORECASE | re.DOTALL)
    if experience_match:
        structured_data["data"]["experience"] = [line.strip() for line in experience_match.group(1).split('\n') if line.strip()]

    # Skills (for resume) - NEW EXTRACTION
    skills_match = re.search(r'Skills:([^\n]+(?:\n[^\n]+)*?)(?:Projects|$)', raw_llm_output, re.IGNORECASE | re.DOTALL)
    if skills_match:
        # Split by comma or newline and clean each skill
        skills_raw = skills_match.group(1).replace('Technical Skills:', '').replace('Soft Skills:', '').strip()
        skills_list = [s.strip() for s in re.split(r'[,;\n]', skills_raw) if s.strip()]
        structured_data["data"]["skills"] = list(set(skills_list)) # Use set for unique skills

    return structured_data


# --- Function to perform OCR using Gemini API ---
def perform_gemini_ocr(image_path):
    """
    Performs OCR and structured data extraction using the Gemini 2.0 Flash API.
    Args:
        image_path (str): The path to the input image file.
    Returns:
        dict: A dictionary containing the structured output from the LLM, or None if an error occurs.
    """
    if not GEMINI_API_KEY:
        print("Error: GEMINI_API_KEY is not set. Please provide your API key.")
        return None

    base64_image = image_to_base64(image_path)
    if not base64_image:
        return None

    # Determine MIME type using mimetypes module for better accuracy
    mime_type, _ = mimetypes.guess_type(image_path)
    if not mime_type or not mime_type.startswith('image/'):
        print(f"Warning: Could not determine valid image MIME type for {image_path}. Defaulting to image/jpeg.")
        mime_type = "image/jpeg" # Fallback

    print(f"Detected MIME type: {mime_type}")
    print(f"Base64 image data length: {len(base64_image)} characters") # Debug print

    # Define the prompt for the LLM - Now asking for structured text, not JSON
    prompt = """Analyze the following image and extract the following information. Present each piece of information on a new line, clearly labeled.

    Document Type: [Identify if it's a Resume, Aadhar Card, Handwritten Document, or Other]
    Name: [Extracted Name]
    Father's Name: [Extracted Father's Name, if applicable]
    Date of Birth: [Extracted Date of Birth, e.g., DD/MM/YYYY]
    Gender: [Extracted Gender, e.g., MALE/FEMALE]
    Aadhar Number: [Extracted 12-digit Aadhar number, if applicable, without spaces or hyphens]
    Phone Number: [Extracted Phone Number(s), if applicable, clean and without other text]
    Email: [Extracted Email Address(es), if applicable]
    Address: [Extracted full mailing address, concise, without "S/O", "VID", Aadhar numbers, phone numbers, emails, website URLs, or other official/repetitive text. Only the physical address.]
    Education: [List of educational qualifications, if applicable, each on a new sub-line]
    Experience: [List of work experience, if applicable, each on a new sub-line]
    Skills: [List of skills, if applicable, each on a new sub-line]
    Extracted Text: [Full raw text content of the document, if it's a handwritten document or general text]

    Ensure that the Aadhar Number, Phone Number, and Address fields contain ONLY the requested information and are free from extraneous text, VIDs, or other document artifacts. If a field is not found, leave it blank or state 'N/A'.
    """

    # Define the API endpoint
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"

    # Define the payload with image data - NO responseSchema now, expect raw text
    payload = {
        "contents": [
            {
                "role": "user",
                "parts": [
                    {"text": prompt},
                    {
                        "inlineData": {
                            "mimeType": mime_type,
                            "data": base64_image
                        }
                    }
                ]
            }
        ]
    }

    headers = {
        "Content-Type": "application/json"
    }

    print("Sending request to Gemini API...")
    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(payload))
        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)
        result = response.json()

        if result.get("candidates") and len(result["candidates"]) > 0 and \
           result["candidates"][0].get("content") and result["candidates"][0]["content"].get("parts") and \
           len(result["candidates"][0]["content"]["parts"]) > 0:
            raw_llm_output = result["candidates"][0]["content"]["parts"][0]["text"]
            print("\n--- Raw LLM Output (for debugging) ---")
            print(raw_llm_output) # Print raw output to see what LLM returned

            # Parse the raw text into structured data
            structured_data = _parse_raw_text_to_structured_data(raw_llm_output)

            return structured_data
        else:
            print(f"Error: No valid response from AI. Response: {result}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"An error occurred during API call: {e}")
        if response is not None:
            print(f"API Response Content: {response.text}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None

# --- Main execution block ---
if __name__ == "__main__":
    # --- Example Usage ---
    # IMPORTANT: Replace 'path/to/your/image.jpg' with the actual path to your image file.
    # You can test with a resume, Aadhar card, or a handwritten note.
    image_file_path = "/content/sh adhar.jpg" # <--- This is the line to change

    if not os.path.exists(image_file_path):
        print(f"Error: The specified image file '{image_file_path}' does not exist.")
        print("Please update 'image_file_path' in the script to a valid image file on your system.")
    else:
        print(f"Processing image: {image_file_path}")

        # Prompt user for the desired field BEFORE performing OCR
        field_to_extract = input("\nEnter the single field you want to extract (e.g., name, address, phoneNumber, email, dob, fatherName, idNumber, extractedText, documentType, skills): ").strip()

        structured_data = perform_gemini_ocr(image_file_path)

        if structured_data:
            print("\n--- Extracted Data for your request ---")
            # Check for fields in 'data' object first
            if 'data' in structured_data and field_to_extract in structured_data['data']:
                print(f"{field_to_extract}: {structured_data['data'][field_to_extract]}")
            # Check for top-level fields
            elif field_to_extract == 'documentType' and 'documentType' in structured_data:
                print(f"documentType: {structured_data['documentType']}")
            elif field_to_extract == 'rawText' and 'rawText' in structured_data:
                print(f"rawText: {structured_data['rawText']}")
            else:
                print(f"Field '{field_to_extract}' not found in the structured output.")
                print("Available fields in 'data' object: " + ", ".join(structured_data.get('data', {}).keys()))
                print("Available top-level fields: documentType, rawText")
        else:
            print("\nFailed to extract structured data.")

    # --- Optional: Local Tesseract OCR (without Gemini's understanding) ---
    # This part is just for demonstrating basic local OCR if you want to see raw text.
    # It does NOT provide structured output like the Gemini API call above.
    # try:
    #     print("\n--- Raw text from local Tesseract OCR (for comparison) ---")
    #     raw_text = pytesseract.image_to_string(Image.open(image_file_path))
    # except pytesseract.TesseractNotFoundError:
    #     print("\nWarning: Tesseract OCR engine not found. Install it to use local OCR.")
    #     print("See: https://tesseract-ocr.github.io/tessdoc/Installation.html")
    # except Exception as e:
    #     print(f"\nError during local Tesseract OCR: {e}")

